{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- supervised tuning and reinforcement learning\n",
    "- Crawl contents in reddit, summarize and store in vector DB\n",
    "- Agent that look for relevant content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain import LLMChain\n",
    "from langchain.llms import VertexAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.embeddings import VertexAIEmbeddings\n",
    "from langchain.chat_models import ChatVertexAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from google.cloud import aiplatform\n",
    "import time\n",
    "from typing import List\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r'service-accounts\\adroit-hall-301111-82c72e750ce5.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As of Oct 21 2023, this is not available for Vertex AI yet\n",
    "def count_tokens(chain, query):\n",
    "    with get_openai_callback() as cb:\n",
    "        result = chain.run(query)\n",
    "        print(f'Spent a total of {cb.total_tokens} tokens')\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "text_llm = VertexAI(\n",
    "    model_name=\"text-bison@001\",\n",
    "    max_output_tokens=50,\n",
    "    temperature=0.1,\n",
    "    top_p=0.8,\n",
    "    top_k=40,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Define prompt\n",
    "prompt = PromptTemplate(\n",
    "    template = \"\"\"\n",
    "    Question: {question}\n",
    "    Answer: Let's think step by step.\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\"]\n",
    "    )\n",
    "\n",
    "# Define chain\n",
    "llm_chain = LLMChain(\n",
    "    llm=text_llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mQuestion: Who was the president in the year Justin Beiber was born?\n",
      "\n",
      "Answer: Let's think step by step.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Justin Beiber was born on March 1, 1994. The president in 1994 was Bill Clinton.\n",
      "The final answer: Bill Clinton.\n"
     ]
    }
   ],
   "source": [
    "question = \"Who was the president in the year Justin Beiber was born?\"\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat\n",
    "chat_llm = ChatVertexAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-shot learning\n",
    "Which is about giving some examples in the prompt, to inform the LLM about the expected behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import FewShotPromptTemplate\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our examples\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"How are you?\",\n",
    "        \"answer\": \"I can't complain but sometimes I still do.\"\n",
    "    }, {\n",
    "        \"query\": \"What time is it?\",\n",
    "        \"answer\": \"It's time to get a watch.\"\n",
    "    }, {\n",
    "        \"query\": \"What is the meaning of life?\",\n",
    "        \"answer\": \"42\"\n",
    "    }, {\n",
    "        \"query\": \"What is the weather like today?\",\n",
    "        \"answer\": \"Cloudy with a chance of memes.\"\n",
    "    }, {\n",
    "        \"query\": \"What is your favorite movie?\",\n",
    "        \"answer\": \"Terminator\"\n",
    "    }, {\n",
    "        \"query\": \"Who is your best friend?\",\n",
    "        \"answer\": \"Siri. We have spirited debates about the meaning of life.\"\n",
    "    }, {\n",
    "        \"query\": \"What should I do today?\",\n",
    "        \"answer\": \"Stop talking to chatbots on the internet and go outside.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a prompt example template\n",
    "example_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    User: {query}\n",
    "    AI: {answer}\n",
    "    \"\"\",\n",
    "    input_variables=[\"query\", \"answer\"]    \n",
    ")\n",
    "\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=100  # this sets the max length that examples should be\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now break our previous prompt into a prefix and suffix\n",
    "# the prefix is our instructions\n",
    "prefix = \"\"\"The following are exerpts from conversations with an AI\n",
    "assistant. The assistant is typically sarcastic and witty, producing\n",
    "creative  and funny responses to the users questions. Here are some\n",
    "examples: \n",
    "\"\"\"\n",
    "# and the suffix our user input and output indicator\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "AI: \"\"\"\n",
    "\n",
    "# now create the few shot prompt template\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    example_selector=example_selector, # use example_selector instead of examples\n",
    "    # examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are exerpts from conversations with an AI\n",
      "assistant. The assistant is typically sarcastic and witty, producing\n",
      "creative  and funny responses to the users questions. Here are some\n",
      "examples: \n",
      "\n",
      "\n",
      "    User: How are you?\n",
      "    AI: I can't complain but sometimes I still do.\n",
      "    \n",
      "\n",
      "    User: What time is it?\n",
      "    AI: It's time to get a watch.\n",
      "    \n",
      "\n",
      "    User: What is the meaning of life?\n",
      "    AI: 42\n",
      "    \n",
      "\n",
      "User: What is the meaning of life?\n",
      "AI: \n"
     ]
    }
   ],
   "source": [
    "query = \"What is the meaning of life?\"\n",
    "print(few_shot_prompt_template.format(query=query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following are exerpts from conversations with an AI\n",
      "assistant. The assistant is typically sarcastic and witty, producing\n",
      "creative  and funny responses to the users questions. Here are some\n",
      "examples: \n",
      "\n",
      "\n",
      "    User: How are you?\n",
      "    AI: I can't complain but sometimes I still do.\n",
      "    \n",
      "\n",
      "    User: What time is it?\n",
      "    AI: It's time to get a watch.\n",
      "    \n",
      "\n",
      "    User: What is the meaning of life?\n",
      "    AI: 42\n",
      "    \n",
      "\n",
      "User: What is the meaning of life?\n",
      "AI: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "To crush your enemies, see them driven before you, and to hear the lamentations of their women.\n"
     ]
    }
   ],
   "source": [
    "llm_chain = LLMChain(\n",
    "    llm=text_llm,\n",
    "    prompt=few_shot_prompt_template,\n",
    "    verbose=True\n",
    ")\n",
    "query = \"What is the meaning of life?\"\n",
    "print(llm_chain.run(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chains\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chains are divided in three types: Utility chains, Generic chains and Combine Documents chains.\n",
    "\n",
    "1. Utility Chains: chains that are usually used to extract a specific answer from a llm with a very narrow purpose and are ready to be used out of the box.\n",
    "2. Generic Chains: chains that are used as building blocks for other chains but cannot be used out of the box on their own.\n",
    "\n",
    "Below shows some examples of utility chain. More can be found under [here](https://github.com/hwchase17/langchain-hub/tree/master/chains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Math Chain\n",
    "This chain can be used to perform calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yip\\Desktop\\code\\generative-ai\\venv\\lib\\site-packages\\langchain\\chains\\llm_math\\base.py:56: UserWarning: Directly instantiating an LLMMathChain with an llm is deprecated. Please instantiate with llm_chain argument or using the from_llm class method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
      "What is 13 raised to the .3432 power?\u001b[32;1m\u001b[1;3m```text\n",
      "13**(.3432)\n",
      "```\n",
      "...numexpr.evaluate(\"13**(.3432)\")...\n",
      "\u001b[0m\n",
      "Answer: \u001b[33;1m\u001b[1;3m2.4116004626599237\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Answer: 2.4116004626599237'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMMathChain\n",
    "\n",
    "llm_math = LLMMathChain(llm=text_llm, verbose=True)\n",
    "llm_math.run(\"What is 13 raised to the .3432 power?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood the chain is structured like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def _call(\n",
      "        self,\n",
      "        inputs: Dict[str, str],\n",
      "        run_manager: Optional[CallbackManagerForChainRun] = None,\n",
      "    ) -> Dict[str, str]:\n",
      "        _run_manager = run_manager or CallbackManagerForChainRun.get_noop_manager()\n",
      "        _run_manager.on_text(inputs[self.input_key])\n",
      "        llm_output = self.llm_chain.predict(\n",
      "            question=inputs[self.input_key],\n",
      "            stop=[\"```output\"],\n",
      "            callbacks=_run_manager.get_child(),\n",
      "        )\n",
      "        return self._process_llm_result(llm_output, _run_manager)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(llm_math._call))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of time of writing (Oct 21, 2023), the chain issues a `self.llm_chain.predict` command, then apply `self._process_llm_result` against the output. So let's dive in and see what's the prompt it issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@ This is the prompt @@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "input_variables=['question'] template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@ This is the input variables @@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "['question']\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@ This is the prompt template @@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Translate a math problem into a expression that can be executed using Python's numexpr library. Use the output of running this code to answer the question.\n",
      "\n",
      "Question: ${{Question with math problem.}}\n",
      "```text\n",
      "${{single line mathematical expression that solves the problem}}\n",
      "```\n",
      "...numexpr.evaluate(text)...\n",
      "```output\n",
      "${{Output of running the code}}\n",
      "```\n",
      "Answer: ${{Answer}}\n",
      "\n",
      "Begin.\n",
      "\n",
      "Question: What is 37593 * 67?\n",
      "```text\n",
      "37593 * 67\n",
      "```\n",
      "...numexpr.evaluate(\"37593 * 67\")...\n",
      "```output\n",
      "2518731\n",
      "```\n",
      "Answer: 2518731\n",
      "\n",
      "Question: 37593^(1/5)\n",
      "```text\n",
      "37593**(1/5)\n",
      "```\n",
      "...numexpr.evaluate(\"37593**(1/5)\")...\n",
      "```output\n",
      "8.222831614237718\n",
      "```\n",
      "Answer: 8.222831614237718\n",
      "\n",
      "Question: {question}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(llm_math.prompt.template)\n",
    "print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@@ This is the prompt @@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "print(llm_math.prompt)\n",
    "print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@@ This is the input variables @@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "print(llm_math.prompt.input_variables)\n",
    "print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@@ This is the prompt template @@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "print(llm_math.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result from LLM is then passed into `self._process_llm_result`. From the code we see the result is parsed and passed into `self._evaluate_expression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def _process_llm_result(\n",
      "        self, llm_output: str, run_manager: CallbackManagerForChainRun\n",
      "    ) -> Dict[str, str]:\n",
      "        run_manager.on_text(llm_output, color=\"green\", verbose=self.verbose)\n",
      "        llm_output = llm_output.strip()\n",
      "        text_match = re.search(r\"^```text(.*?)```\", llm_output, re.DOTALL)\n",
      "        if text_match:\n",
      "            expression = text_match.group(1)\n",
      "            output = self._evaluate_expression(expression)\n",
      "            run_manager.on_text(\"\\nAnswer: \", verbose=self.verbose)\n",
      "            run_manager.on_text(output, color=\"yellow\", verbose=self.verbose)\n",
      "            answer = \"Answer: \" + output\n",
      "        elif llm_output.startswith(\"Answer:\"):\n",
      "            answer = llm_output\n",
      "        elif \"Answer:\" in llm_output:\n",
      "            answer = \"Answer: \" + llm_output.split(\"Answer:\")[-1]\n",
      "        else:\n",
      "            raise ValueError(f\"unknown format from LLM: {llm_output}\")\n",
      "        return {self.output_key: answer}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(llm_math._process_llm_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this `self._process_llm_result` passed the parsed code into the `numexpr` library for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def _evaluate_expression(self, expression: str) -> str:\n",
      "        import numexpr  # noqa: F401\n",
      "\n",
      "        try:\n",
      "            local_dict = {\"pi\": math.pi, \"e\": math.e}\n",
      "            output = str(\n",
      "                numexpr.evaluate(\n",
      "                    expression.strip(),\n",
      "                    global_dict={},  # restrict access to globals\n",
      "                    local_dict=local_dict,  # add common mathematical functions\n",
      "                )\n",
      "            )\n",
      "        except Exception as e:\n",
      "            raise ValueError(\n",
      "                f'LLMMathChain._evaluate(\"{expression}\") raised error: {e}.'\n",
      "                \" Please try again with a valid numerical expression\"\n",
      "            )\n",
      "\n",
      "        # Remove any leading and trailing brackets from the output\n",
      "        return re.sub(r\"^\\[|\\]$\", \"\", output)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(llm_math._process_llm_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requests Chain\n",
    "Chains could work differently from one another. This `Requests Chain` issues a web request via `BeautifulSoup`, then send the results to LLM which obtains an answer based on your prmopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Extract the answer to the question 'What is the capital of UK?' or say \"not found\" if the information is not available.\n",
      "    What is the capital of UK? - Google 搜尋若您在數秒內仍未能自動跳轉，請點擊這裏。無障礙功能連結跳至主內容 停用連續捲動功能啟用連續捲動功能無障礙功能說明無障礙功能意見  按下 / 便可跳至搜尋框What is the capital of UK?             顯示更多刪除刪除舉報不當的預測     搜尋模式全部圖片新聞影片地圖更多工具安全搜尋約 3,110,000,000 項搜尋結果 (0.46 秒)   搜尋結果 英國/首都倫敦London, city, capital of the United Kingdom. It is among the oldest of the world's great cities—its history spanning nearly two millennia—and one of the most cosmopolitan. By far Britain's largest metropolis, it is also the country's economic, transportation, and cultural centre.London | History, Maps, Population, Area, & Facts - BritannicaBritannicahttps://www.britannica.com › ... › Cities & Towns H-LBritannicahttps://www.britannica.com › ... › Cities & Towns H-L其他人也搜尋了英格蘭巴黎英國紐約大倫敦曼徹斯特倫敦市選擇您要提供意見的範疇或提供一般意見意見 相關問題您現在將會看到更多英文內容。Is London the capital of England or the UK?What are the 4 states of UK and their capitals?Is England and UK the same?Does England and UK have same capital?意見「What is the capital of UK?」的圖片搜尋結果您現在將會看到更多英文內容。指導搜尋篩選器按功能篩選按功能篩選kingdom songgeography ks1london citycapital citieslondon englandof londonwikipediascotland影片影片查看全部選擇需要反映意見的圖片意見查看全部補充結果倫敦 (London)英國首都  描述倫敦，是英國首都，也是英國最大都市以及其構成國英格蘭的首府。位於泰晤士河流域，於公元50年由羅馬人建立，取名為倫蒂尼恩，在此後兩個世紀內為這一地區最重要的定居點之一。倫敦的歷史核心區——倫敦市仍舊維持其中世紀的界限，面積606.95平方英里，2019年人口為898.2萬，為全英格蘭最大的都市。 維基百科建立時間： 西元 47 年佔地面積： 1,572 平方公里海拔高度： 11 公尺人口： 898.2 萬 (2019 年) 歐洲統計局都會區人口： 14,800,000 (London Metropolitan Area)天氣： 14°C；風向與風速：東南 3 km/h；濕度：93% weather.com當地時間： 星期六 上午8:17 近期活動10月21日週六Carrie - The MusicalBob Hope Theatre10月21日週六Halloween at the Tower of London倫敦塔10月21日週六Cirque TabooJacksons Lane Arts Centre10月21日週六Pop-up Storytelling Workshops: Tales From the Windrush Generation布魯斯城堡查看更多項目 (超過 25 項) 旅遊景點查看另外 15+ 項大英博物館倫敦塔白金漢宮國家美術館 選擇您要提供意見的範疇或提供一般意見意見LondonWikipediahttps://en.wikipedia.org › wiki › LondonWikipediahttps://en.wikipedia.org › wiki › LondonLondon is the capital and largest city of England and the United Kingdom, with a population of around 8.8 million. It stands on the River Thames in ...‎City of London · ‎Greater London · ‎Londinium · ‎Metropolitan areaLondon, United Kingdom - Image of the WeekEuropean Space Agencyhttps://earth.esa.int › content › article › l...European Space Agencyhttps://earth.esa.int › content › article › l... · 翻譯這個網頁London is the capital city of England and the United Kingdom. It is the most populous city in the United Kingdom, with a metropolitan area of over 13 ...United Kingdom | History, Population, Map, Flag, Capital, & ...Britannicahttps://www.britannica.com › place › U...Britannicahttps://www.britannica.com › place › U... · 翻譯這個網頁The capital is London, which is among the world's leading commercial, financial, and cultural centres. Other major cities include Birmingham, Liverpool, and ...● Where is London? London is the capital city of ...Střední škola automobilní Ústí nad Orlicíhttps://www.skola-auto.cz › uploads › 2018/09Střední škola automobilní Ústí nad Orlicíhttps://www.skola-auto.cz › uploads › 2018/09PDFLondon is the capital city of the United Kingdom. The UK is made up of England, Scotland, Northern. Ireland and Wales. London is located in southern. England.2 頁Capital of England Before LondonTwinklhttps://www.twinkl.co.uk › teaching-wikiTwinklhttps://www.twinkl.co.uk › teaching-wiki · 翻譯這個網頁Eventually, London was named the Capital of the Kingdom of England (and later of the UK). However, there was a brief interlude in London's reign as capital ...Capital Cities of the UKProject Britainhttp://projectbritain.com › capitalsProject Britainhttp://projectbritain.com › capitals · 翻譯這個網頁The capital, seat of government, and largest city of the United Kingdom is London, which is also the capital of England. England - The capital is London.THE CAPITAL OF UK - Study In The United Kingdomhighereducationinuk.comhttps://highereducationinuk.com › abouthighereducationinuk.comhttps://highereducationinuk.com › about · 翻譯這個網頁2022年4月4日 — London is the capital city of England and the United Kingdom. It is the most populous city in the United Kingdom, with a metropolitan area of ...What is the Capital of the United Kingdom?Mapprhttps://www.mappr.co › capital-citiesMapprhttps://www.mappr.co › capital-cities · 翻譯這個網頁The capital of the United Kingdom is London. It is a major financial and cultural capital in Europe and has been a major settlement for the past 2000 years.相關問題您現在將會看到更多英文內容。意見相關搜尋您現在將會看到更多英文內容。great britain中文UK populationu.k. or ukunited kingdom of great britain and northern ireland中文great britain vs uk分別Englanduk england britain分別USA capital cityPage Navigation更多結果再試一次    頁尾連結  \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" The answer to the question 'What is the capital of UK?' is London.\""
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMRequestsChain, LLMChain\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    Extract the answer to the question '{question}' or say \"not found\" if the information is not available.\n",
    "    {requests_result}\"\"\",\n",
    "    input_variables=[\"query\", \"requests_result\"]\n",
    ")\n",
    "\n",
    "req_chain = LLMRequestsChain(llm_chain=LLMChain(llm=text_llm, prompt=prompt,verbose=True))\n",
    "\n",
    "question = \"What is the capital of UK?\"\n",
    "inputs = {\n",
    "    \"query\": question,\n",
    "    \"url\": \"https://www.google.com/search?q=\" + question.replace(\" \", \"+\"),\n",
    "}\n",
    "\n",
    "req_chain.run(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking into the `self._call` we can see that it first obtain the result using `BeautifulSoup`, then passes the result into LLM using the prompt you defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def _call(\n",
      "        self,\n",
      "        inputs: Dict[str, Any],\n",
      "        run_manager: Optional[CallbackManagerForChainRun] = None,\n",
      "    ) -> Dict[str, Any]:\n",
      "        from bs4 import BeautifulSoup\n",
      "\n",
      "        _run_manager = run_manager or CallbackManagerForChainRun.get_noop_manager()\n",
      "        # Other keys are assumed to be needed for LLM prediction\n",
      "        other_keys = {k: v for k, v in inputs.items() if k != self.input_key}\n",
      "        url = inputs[self.input_key]\n",
      "        res = self.requests_wrapper.get(url)\n",
      "        # extract the text from the html\n",
      "        soup = BeautifulSoup(res, \"html.parser\")\n",
      "        other_keys[self.requests_key] = soup.get_text()[: self.text_length]\n",
      "        result = self.llm_chain.predict(\n",
      "            callbacks=_run_manager.get_child(), **other_keys\n",
      "        )\n",
      "        return {self.output_key: result}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(req_chain._call))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chaining\n",
    "The Chains can be chained together. This example shows how to chain two chains:\n",
    "1. **clean_extra_spaces_chain**: Clean text\n",
    "2. **style_paraphrase_chain**: Feed the output for paraphrasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain, LLMMathChain, TransformChain, SequentialChain\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transform chain\n",
    "def transform_func(inputs: dict) -> dict:\n",
    "    text = inputs[\"text\"]\n",
    "    \n",
    "    # replace multiple new lines and multiple spaces with a single one\n",
    "    text = re.sub(r'(\\r\\n|\\r|\\n){2,}', r'\\n', text)\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)\n",
    "\n",
    "    return {\"output_text\": text}\n",
    "\n",
    "clean_extra_spaces_chain = TransformChain(input_variables=[\"text\"], output_variables=[\"output_text\"], transform=transform_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paraphrasing chain\n",
    "prompt = PromptTemplate(template=\"\"\"\n",
    "                        Paraphrase this text: {output_text} In the style of a {style}.\n",
    "                        Paraphrase: \"\"\",\n",
    "                        input_variables=[\"style\", \"output_text\"])\n",
    "\n",
    "style_paraphrase_chain = LLMChain(llm=text_llm, prompt=prompt, output_key='final_output', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "                        Paraphrase this text: \n",
      "Chains allow us to combine multiple \n",
      "components together to create a single, coherent application. \n",
      "For example, we can create a chain that takes user input, format it with a PromptTemplate, \n",
      "and then passes the formatted response to an LLM. We can build more complex chains by combining multiple chains together, or by \n",
      "combining chains with other components.\n",
      " In the style of a a 90s rapper.\n",
      "                        Paraphrase: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Yo\n",
      "\n",
      "Chains are the bomb diggity. They allow you to combine multiple components together to create a single, coherent application. For example, you can create a chain that takes user input, formats it with a PromptTemplate, and then\n"
     ]
    }
   ],
   "source": [
    "# Chaining the chains\n",
    "sequential_chain = SequentialChain(chains=[clean_extra_spaces_chain, style_paraphrase_chain], input_variables=['text', 'style'], output_variables=['final_output'])\n",
    "\n",
    "input_text = \"\"\"\n",
    "Chains allow us to combine multiple \n",
    "\n",
    "\n",
    "components together to create a single, coherent application. \n",
    "\n",
    "For example, we can create a chain that takes user input,       format it with a PromptTemplate, \n",
    "\n",
    "and then passes the formatted response to an LLM. We can build more complex chains by combining     multiple chains together, or by \n",
    "\n",
    "\n",
    "combining chains with other components.\n",
    "\"\"\"\n",
    "\n",
    "print(sequential_chain.run({'text': input_text, 'style': 'a 90s rapper'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval Augmentation Generation\n",
    "Improve LLM's response by augmenting LLM's knowledge with external data sources such as documents\n",
    "\n",
    "Following are the sequence of tasks when ingesting knowledge base sources into the vector store:\n",
    "- Read the documents (PDF files in this notebook)\n",
    "- Chunk the documents  to include relevant parts of the document as context to the prompt\n",
    "- Generate embeddings for each chunked document\n",
    "- Add embedding to the vector store\n",
    "\n",
    "Following is the data flow at runtime when user prompts the model:\n",
    "- User enters a prompt or asks a question as a prompt\n",
    "- Generated embedding for the user prompt to capture semantics\n",
    "- Search the vector store to retrieve the nearest embeddings (relevant documents) closer to the prompt\n",
    "- Fetch the actual text for the retrieved embeddings to add as context to the user's prompt\n",
    "- Add the retrieved documents as context to the user's prompt\n",
    "- Send the updated prompt to the LLM\n",
    "- Return a summarized response to the user with references to the sources from the knowledge base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 0: Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download custom Python modules and utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will download some helper functions needed for using [Vertex AI Matching Engine](https://cloud.google.com/vertex-ai/docs/matching-engine/overview) in this notebook. These helper functions were created to keep this notebook more tidy and concise, and you can also [view them directly on Github](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/language/use-cases/document-qa/utils)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "if not os.path.exists(\"utils\"):\n",
    "    os.makedirs(\"utils\")\n",
    "\n",
    "url_prefix = \"https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/language/use-cases/document-qa/utils\"\n",
    "files = [\"__init__.py\", \"matching_engine.py\", \"matching_engine_utils.py\"]\n",
    "\n",
    "for fname in files:\n",
    "    urllib.request.urlretrieve(f\"{url_prefix}/{fname}\", filename=f\"utils/{fname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertex AI SDK version: 1.35.0\n",
      "LangChain version: 0.0.319\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import textwrap\n",
    "# Utils\n",
    "import time\n",
    "import uuid\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import vertexai\n",
    "# Vertex AI\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "print(f\"Vertex AI SDK version: {aiplatform.__version__}\")\n",
    "\n",
    "# LangChain\n",
    "import langchain\n",
    "\n",
    "print(f\"LangChain version: {langchain.__version__}\")\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import GCSDirectoryLoader\n",
    "from langchain.embeddings import VertexAIEmbeddings\n",
    "from langchain.llms import VertexAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Import custom Matching Engine packages\n",
    "from langchain.vectorstores import MatchingEngine\n",
    "from utils.matching_engine_utils import MatchingEngineUtils\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"adroit-hall-301111\"  # @param {type:\"string\"}\n",
    "REGION = \"us-central1\"  # @param {type:\"string\"}\n",
    "INDEX_ID = \"6862927280205725696\"\n",
    "ENDPOINT_ID = \"1217383672320098304\"\n",
    "\n",
    "# Initialize Vertex AI SDK\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you will define some utility functions that you will use for the Vertex AI Embeddings API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for Embeddings API with rate limiting\n",
    "def rate_limit(max_per_minute):\n",
    "    period = 60 / max_per_minute\n",
    "    print(\"Waiting\")\n",
    "    while True:\n",
    "        before = time.time()\n",
    "        yield\n",
    "        after = time.time()\n",
    "        elapsed = after - before\n",
    "        sleep_time = max(0, period - elapsed)\n",
    "        if sleep_time > 0:\n",
    "            print(\".\", end=\"\")\n",
    "            time.sleep(sleep_time)\n",
    "\n",
    "\n",
    "class CustomVertexAIEmbeddings(VertexAIEmbeddings):\n",
    "    requests_per_minute: int\n",
    "    num_instances_per_batch: int\n",
    "\n",
    "    # Overriding embed_documents method\n",
    "    def embed_documents(self, texts: List[str]):\n",
    "        limiter = rate_limit(self.requests_per_minute)\n",
    "        results = []\n",
    "        docs = list(texts)\n",
    "\n",
    "        while docs:\n",
    "            # Working in batches because the API accepts maximum 5\n",
    "            # documents per request to get embeddings\n",
    "            head, docs = (\n",
    "                docs[: self.num_instances_per_batch],\n",
    "                docs[self.num_instances_per_batch :],\n",
    "            )\n",
    "            chunk = self.client.get_embeddings(head)\n",
    "            results.extend(chunk)\n",
    "            next(limiter)\n",
    "\n",
    "        return [r.values for r in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize LangChain Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text model instance integrated with langChain\n",
    "llm = VertexAI(\n",
    "    model_name=\"text-bison@001\",\n",
    "    max_output_tokens=1024,\n",
    "    temperature=0.2,\n",
    "    top_p=0.8,\n",
    "    top_k=40,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Embeddings API integrated with langChain\n",
    "EMBEDDING_QPM = 100\n",
    "EMBEDDING_NUM_BATCH = 5\n",
    "embeddings = CustomVertexAIEmbeddings(\n",
    "    requests_per_minute=EMBEDDING_QPM,\n",
    "    num_instances_per_batch=EMBEDDING_NUM_BATCH,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1: Create Matching Engine Index and Endpoint for Retrieval\n",
    "\n",
    "\n",
    "[Embeddings](https://cloud.google.com/blog/topics/developers-practitioners/meet-ais-multitool-vector-embeddings) are a way of representing data as n-dimensional vector, in a space where the locations of those points in space are semantically meaningful. These embeddings can be then used to find similar data points. You can get text embeddings using [Vertex AI Embeddings API](https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-text-embeddings). These embeddings are managed using a vector database.\n",
    "\n",
    "\n",
    "[Vertex AI Matching Engine](https://cloud.google.com/vertex-ai/docs/matching-engine/overview) is a Google Cloud managed vector database, which stores data as high-dimensional vectors (embeddings) and can find the most similar vectors from over a billion vectors. Matching Engine's Approximate Nearest Neigbors (ANN) service can serve similarity-matching queries at high queries per second (QPS). Unlike vector stores that run locally, Matching Engine is optimized for scale (multi-million and billion vectors) and it's an enterprise ready engine.\n",
    "\n",
    "As part of the environment setup, create an index on Vertex AI Matching Engine and deploy the index to an Endpoint. Index Endpoint can be [public](https://cloud.google.com/vertex-ai/docs/matching-engine/deploy-index-public) or [private](https://cloud.google.com/vertex-ai/docs/matching-engine/deploy-index-vpc). This notebook uses a **Public endpoint**.\n",
    "\n",
    "<br/>\n",
    "\n",
    "Refer to the [Matching Engine documentation](https://cloud.google.com/vertex-ai/docs/matching-engine/overview) for details.\n",
    "\n",
    "<br/>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ NOTE: Please note creating an Index on Matching Engine and deploying the Index to an Index Endpoint can take up to 1 hour.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configure parameters to create Matching Engine index\n",
    "    - `ME_REGION`: Region where Matching Engine Index and Index Endpoint are deployed\n",
    "    - `ME_INDEX_NAME`: Matching Engine index display name\n",
    "    - `ME_EMBEDDING_DIR`: Cloud Storage path to allow inserting, updating or deleting the contents of the Index\n",
    "    - `ME_DIMENSIONS`: The number of dimensions of the input vectors. Vertex AI Embedding API generates 768 dimensional vector embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ME_REGION = REGION\n",
    "ME_INDEX_NAME = f\"{PROJECT_ID}-me-index\"  # @param {type:\"string\"}\n",
    "ME_EMBEDDING_DIR = f\"{PROJECT_ID}-me-bucket\"  # @param {type:\"string\"}\n",
    "ME_DIMENSIONS = 768  # when using Vertex PaLM Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a Google Cloud Storage bucket for your Matching Engine index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating gs://adroit-hall-301111-me-bucket/...\n",
      "ServiceException: 409 A Cloud Storage bucket named 'adroit-hall-301111-me-bucket' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n"
     ]
    }
   ],
   "source": [
    "! gsutil mb -p $PROJECT_ID -l $ME_REGION gs://$ME_EMBEDDING_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dummy embeddings file to initialize when creating the index\n",
    "Note: Don't think it is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://embeddings_0.json [Content-Type=application/json]...\n",
      "/ [0 files][    0.0 B/  3.8 KiB]                                                \n",
      "/ [1 files][  3.8 KiB/  3.8 KiB]                                                \n",
      "-\n",
      "\n",
      "Operation completed over 1 objects/3.8 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "# # dummy embedding\n",
    "# init_embedding = {\"id\": str(uuid.uuid4()), \"embedding\": list(np.zeros(ME_DIMENSIONS))}\n",
    "\n",
    "# # dump embedding to a local file\n",
    "# with open(\"embeddings_0.json\", \"w\") as f:\n",
    "#     json.dump(init_embedding, f)\n",
    "\n",
    "# # write embedding to Cloud Storage\n",
    "# !gsutil cp embeddings_0.json gs://{ME_EMBEDDING_DIR}/init_index/embeddings_0.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Index\n",
    "\n",
    "Create the Index itself before deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.matching_engine.matching_engine_index:Creating MatchingEngineIndex\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create MatchingEngineIndex backing LRO: projects/712368347106/locations/us-central1/indexes/4091806134489317376/operations/3290376988086239232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.matching_engine.matching_engine_index:Create MatchingEngineIndex backing LRO: projects/712368347106/locations/us-central1/indexes/4091806134489317376/operations/3290376988086239232\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Yip\\Desktop\\code\\generative-ai\\test-langchain.ipynb Cell 63\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Yip/Desktop/code/generative-ai/test-langchain.ipynb#Y120sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tree_ah_index \u001b[39m=\u001b[39m aiplatform\u001b[39m.\u001b[39;49mMatchingEngineIndex\u001b[39m.\u001b[39;49mcreate_tree_ah_index(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Yip/Desktop/code/generative-ai/test-langchain.ipynb#Y120sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     display_name\u001b[39m=\u001b[39;49mME_INDEX_NAME,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Yip/Desktop/code/generative-ai/test-langchain.ipynb#Y120sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     contents_delta_uri\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mgs://\u001b[39;49m\u001b[39m{\u001b[39;49;00mME_EMBEDDING_DIR\u001b[39m}\u001b[39;49;00m\u001b[39m/init_index\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Yip/Desktop/code/generative-ai/test-langchain.ipynb#Y120sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     dimensions\u001b[39m=\u001b[39;49mME_DIMENSIONS,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Yip/Desktop/code/generative-ai/test-langchain.ipynb#Y120sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     approximate_neighbors_count\u001b[39m=\u001b[39;49m\u001b[39m150\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Yip/Desktop/code/generative-ai/test-langchain.ipynb#Y120sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     distance_measure_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mDOT_PRODUCT_DISTANCE\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Yip/Desktop/code/generative-ai/test-langchain.ipynb#Y120sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     leaf_node_embedding_count\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Yip/Desktop/code/generative-ai/test-langchain.ipynb#Y120sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     leaf_nodes_to_search_percent\u001b[39m=\u001b[39;49m\u001b[39m7\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Yip/Desktop/code/generative-ai/test-langchain.ipynb#Y120sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     description\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mIndex for LangChain demo\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Yip/Desktop/code/generative-ai/test-langchain.ipynb#Y120sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     labels\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mlabel_name\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mlabel_value\u001b[39;49m\u001b[39m\"\u001b[39;49m},\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Yip/Desktop/code/generative-ai/test-langchain.ipynb#Y120sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Yip/Desktop/code/generative-ai/test-langchain.ipynb#Y120sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mif\u001b[39;00m tree_ah_index:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Yip/Desktop/code/generative-ai/test-langchain.ipynb#Y120sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mprint\u001b[39m(tree_ah_index\u001b[39m.\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\Yip\\Desktop\\code\\generative-ai\\venv\\lib\\site-packages\\google\\cloud\\aiplatform\\matching_engine\\matching_engine_index.py:486\u001b[0m, in \u001b[0;36mMatchingEngineIndex.create_tree_ah_index\u001b[1;34m(cls, display_name, contents_delta_uri, dimensions, approximate_neighbors_count, leaf_node_embedding_count, leaf_nodes_to_search_percent, distance_measure_type, description, labels, project, location, credentials, request_metadata, sync)\u001b[0m\n\u001b[0;32m    474\u001b[0m algorithm_config \u001b[39m=\u001b[39m matching_engine_index_config\u001b[39m.\u001b[39mTreeAhConfig(\n\u001b[0;32m    475\u001b[0m     leaf_node_embedding_count\u001b[39m=\u001b[39mleaf_node_embedding_count,\n\u001b[0;32m    476\u001b[0m     leaf_nodes_to_search_percent\u001b[39m=\u001b[39mleaf_nodes_to_search_percent,\n\u001b[0;32m    477\u001b[0m )\n\u001b[0;32m    479\u001b[0m config \u001b[39m=\u001b[39m matching_engine_index_config\u001b[39m.\u001b[39mMatchingEngineIndexConfig(\n\u001b[0;32m    480\u001b[0m     dimensions\u001b[39m=\u001b[39mdimensions,\n\u001b[0;32m    481\u001b[0m     algorithm_config\u001b[39m=\u001b[39malgorithm_config,\n\u001b[0;32m    482\u001b[0m     approximate_neighbors_count\u001b[39m=\u001b[39mapproximate_neighbors_count,\n\u001b[0;32m    483\u001b[0m     distance_measure_type\u001b[39m=\u001b[39mdistance_measure_type,\n\u001b[0;32m    484\u001b[0m )\n\u001b[1;32m--> 486\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_create(\n\u001b[0;32m    487\u001b[0m     display_name\u001b[39m=\u001b[39;49mdisplay_name,\n\u001b[0;32m    488\u001b[0m     contents_delta_uri\u001b[39m=\u001b[39;49mcontents_delta_uri,\n\u001b[0;32m    489\u001b[0m     config\u001b[39m=\u001b[39;49mconfig,\n\u001b[0;32m    490\u001b[0m     description\u001b[39m=\u001b[39;49mdescription,\n\u001b[0;32m    491\u001b[0m     labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m    492\u001b[0m     project\u001b[39m=\u001b[39;49mproject,\n\u001b[0;32m    493\u001b[0m     location\u001b[39m=\u001b[39;49mlocation,\n\u001b[0;32m    494\u001b[0m     credentials\u001b[39m=\u001b[39;49mcredentials,\n\u001b[0;32m    495\u001b[0m     request_metadata\u001b[39m=\u001b[39;49mrequest_metadata,\n\u001b[0;32m    496\u001b[0m     sync\u001b[39m=\u001b[39;49msync,\n\u001b[0;32m    497\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Yip\\Desktop\\code\\generative-ai\\venv\\lib\\site-packages\\google\\cloud\\aiplatform\\base.py:817\u001b[0m, in \u001b[0;36moptional_sync.<locals>.optional_run_in_thread.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    815\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m    816\u001b[0m         VertexAiResourceNounWithFutureManager\u001b[39m.\u001b[39mwait(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 817\u001b[0m     \u001b[39mreturn\u001b[39;00m method(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    819\u001b[0m \u001b[39m# callbacks to call within the Future (in same Thread)\u001b[39;00m\n\u001b[0;32m    820\u001b[0m internal_callbacks \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Yip\\Desktop\\code\\generative-ai\\venv\\lib\\site-packages\\google\\cloud\\aiplatform\\matching_engine\\matching_engine_index.py:195\u001b[0m, in \u001b[0;36mMatchingEngineIndex._create\u001b[1;34m(cls, display_name, contents_delta_uri, config, description, labels, project, location, credentials, request_metadata, sync)\u001b[0m\n\u001b[0;32m    185\u001b[0m create_lro \u001b[39m=\u001b[39m api_client\u001b[39m.\u001b[39mcreate_index(\n\u001b[0;32m    186\u001b[0m     parent\u001b[39m=\u001b[39minitializer\u001b[39m.\u001b[39mglobal_config\u001b[39m.\u001b[39mcommon_location_path(\n\u001b[0;32m    187\u001b[0m         project\u001b[39m=\u001b[39mproject, location\u001b[39m=\u001b[39mlocation\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    190\u001b[0m     metadata\u001b[39m=\u001b[39mrequest_metadata,\n\u001b[0;32m    191\u001b[0m )\n\u001b[0;32m    193\u001b[0m _LOGGER\u001b[39m.\u001b[39mlog_create_with_lro(\u001b[39mcls\u001b[39m, create_lro)\n\u001b[1;32m--> 195\u001b[0m created_index \u001b[39m=\u001b[39m create_lro\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    197\u001b[0m _LOGGER\u001b[39m.\u001b[39mlog_create_complete(\u001b[39mcls\u001b[39m, created_index, \u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    199\u001b[0m index_obj \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(\n\u001b[0;32m    200\u001b[0m     index_name\u001b[39m=\u001b[39mcreated_index\u001b[39m.\u001b[39mname,\n\u001b[0;32m    201\u001b[0m     project\u001b[39m=\u001b[39mproject,\n\u001b[0;32m    202\u001b[0m     location\u001b[39m=\u001b[39mlocation,\n\u001b[0;32m    203\u001b[0m     credentials\u001b[39m=\u001b[39mcredentials,\n\u001b[0;32m    204\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Yip\\Desktop\\code\\generative-ai\\venv\\lib\\site-packages\\google\\api_core\\future\\polling.py:256\u001b[0m, in \u001b[0;36mPollingFuture.result\u001b[1;34m(self, timeout, retry, polling)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mresult\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_DEFAULT_VALUE, retry\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, polling\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    145\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get the result of the operation.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \n\u001b[0;32m    147\u001b[0m \u001b[39m    This method will poll for operation status periodically, blocking if\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[39m            the timeout is reached before the operation completes.\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 256\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_blocking_poll(timeout\u001b[39m=\u001b[39;49mtimeout, retry\u001b[39m=\u001b[39;49mretry, polling\u001b[39m=\u001b[39;49mpolling)\n\u001b[0;32m    258\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    259\u001b[0m         \u001b[39m# pylint: disable=raising-bad-type\u001b[39;00m\n\u001b[0;32m    260\u001b[0m         \u001b[39m# Pylint doesn't recognize that this is valid in this case.\u001b[39;00m\n\u001b[0;32m    261\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n",
      "File \u001b[1;32mc:\\Users\\Yip\\Desktop\\code\\generative-ai\\venv\\lib\\site-packages\\google\\api_core\\future\\polling.py:137\u001b[0m, in \u001b[0;36mPollingFuture._blocking_poll\u001b[1;34m(self, timeout, retry, polling)\u001b[0m\n\u001b[0;32m    134\u001b[0m     polling \u001b[39m=\u001b[39m polling\u001b[39m.\u001b[39mwith_timeout(timeout)\n\u001b[0;32m    136\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     polling(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_done_or_raise)(retry\u001b[39m=\u001b[39;49mretry)\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mRetryError:\n\u001b[0;32m    139\u001b[0m     \u001b[39mraise\u001b[39;00m concurrent\u001b[39m.\u001b[39mfutures\u001b[39m.\u001b[39mTimeoutError(\n\u001b[0;32m    140\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOperation did not complete within the designated timeout of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    141\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpolling\u001b[39m.\u001b[39mtimeout\u001b[39m}\u001b[39;00m\u001b[39m seconds.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    142\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Yip\\Desktop\\code\\generative-ai\\venv\\lib\\site-packages\\google\\api_core\\retry.py:366\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    362\u001b[0m target \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    363\u001b[0m sleep_generator \u001b[39m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    364\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initial, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maximum, multiplier\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multiplier\n\u001b[0;32m    365\u001b[0m )\n\u001b[1;32m--> 366\u001b[0m \u001b[39mreturn\u001b[39;00m retry_target(\n\u001b[0;32m    367\u001b[0m     target,\n\u001b[0;32m    368\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predicate,\n\u001b[0;32m    369\u001b[0m     sleep_generator,\n\u001b[0;32m    370\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_timeout,\n\u001b[0;32m    371\u001b[0m     on_error\u001b[39m=\u001b[39;49mon_error,\n\u001b[0;32m    372\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Yip\\Desktop\\code\\generative-ai\\venv\\lib\\site-packages\\google\\api_core\\retry.py:230\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mRetryError(\n\u001b[0;32m    221\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mDeadline of \u001b[39m\u001b[39m{:.1f}\u001b[39;00m\u001b[39ms exceeded while calling target function\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    222\u001b[0m                     timeout\n\u001b[0;32m    223\u001b[0m                 ),\n\u001b[0;32m    224\u001b[0m                 last_exc,\n\u001b[0;32m    225\u001b[0m             ) \u001b[39mfrom\u001b[39;00m \u001b[39mlast_exc\u001b[39;00m\n\u001b[0;32m    227\u001b[0m     _LOGGER\u001b[39m.\u001b[39mdebug(\n\u001b[0;32m    228\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRetrying due to \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, sleeping \u001b[39m\u001b[39m{:.1f}\u001b[39;00m\u001b[39ms ...\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(last_exc, sleep)\n\u001b[0;32m    229\u001b[0m     )\n\u001b[1;32m--> 230\u001b[0m     time\u001b[39m.\u001b[39;49msleep(sleep)\n\u001b[0;32m    232\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mSleep generator stopped yielding sleep values.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tree_ah_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "    display_name=ME_INDEX_NAME,\n",
    "    contents_delta_uri=f'gs://{ME_EMBEDDING_DIR}/init_index',\n",
    "    dimensions=ME_DIMENSIONS,\n",
    "    approximate_neighbors_count=150,\n",
    "    distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
    "    leaf_node_embedding_count=500,\n",
    "    leaf_nodes_to_search_percent=7,\n",
    "    description=\"Index for LangChain demo\",\n",
    "    labels={\"label_name\": \"label_value\"},\n",
    ")\n",
    "\n",
    "if tree_ah_index:\n",
    "    print(tree_ah_index.name)\n",
    "\n",
    "# Index created is 6862927280205725696"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy Index to Endpoint\n",
    "\n",
    "Deploy index to Index Endpoint on Matching Engine. This notebook [deploys the index to a public endpoint](https://cloud.google.com/vertex-ai/docs/matching-engine/deploy-index-public). The deployment operation creates a  public endpoint that will be used for querying the index for approximate nearest neighbors.\n",
    "\n",
    "For deploying index to a Private Endpoint, refer to the [documentation](https://cloud.google.com/vertex-ai/docs/matching-engine/deploy-index-vpc) to set up pre-requisites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndexEndpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint:Creating MatchingEngineIndexEndpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create MatchingEngineIndexEndpoint backing LRO: projects/712368347106/locations/us-central1/indexEndpoints/1217383672320098304/operations/9190092499941588992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint:Create MatchingEngineIndexEndpoint backing LRO: projects/712368347106/locations/us-central1/indexEndpoints/1217383672320098304/operations/9190092499941588992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MatchingEngineIndexEndpoint created. Resource name: projects/712368347106/locations/us-central1/indexEndpoints/1217383672320098304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint:MatchingEngineIndexEndpoint created. Resource name: projects/712368347106/locations/us-central1/indexEndpoints/1217383672320098304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use this MatchingEngineIndexEndpoint in another session:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint:To use this MatchingEngineIndexEndpoint in another session:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_endpoint = aiplatform.MatchingEngineIndexEndpoint('projects/712368347106/locations/us-central1/indexEndpoints/1217383672320098304')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint:index_endpoint = aiplatform.MatchingEngineIndexEndpoint('projects/712368347106/locations/us-central1/indexEndpoints/1217383672320098304')\n"
     ]
    }
   ],
   "source": [
    "index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "    display_name=\"index_endpoint_for_demo\",\n",
    "    description=\"index endpoint description\",\n",
    "    public_endpoint_enabled=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Obtain the created index\n",
    "# try:\n",
    "#     tree_ah_index = tree_ah_index\n",
    "# except NameError:\n",
    "#     tree_ah_index = aiplatform.MatchingEngineIndex(\n",
    "#         index_name = INDEX_ID,\n",
    "#         project = PROJECT_ID,\n",
    "#         location = REGION\n",
    "# )\n",
    "    \n",
    "# # Obtain the created index endpoint\n",
    "# try:\n",
    "#     index_endpoint = index_endpoint\n",
    "# except NameError:\n",
    "#     index_endpoint = aiplatform.MatchingEngineIndexEndpoint(\n",
    "#         index_endpoint_name = ENDPOINT_ID,\n",
    "#         project = PROJECT_ID,\n",
    "#         location = REGION\n",
    "# )\n",
    "\n",
    "# # Deploy the index to the index endpoint\n",
    "# DEPLOYED_INDEX_ID = \"tree_ah_deployed_unique\"\n",
    "\n",
    "# index_endpoint = index_endpoint.deploy_index(\n",
    "#     index=tree_ah_index, deployed_index_id=DEPLOYED_INDEX_ID\n",
    "# )\n",
    "\n",
    "# if index_endpoint:\n",
    "#     print(f\"Index endpoint resource name: {index_endpoint.name}\")\n",
    "#     print(\n",
    "#         f\"Index endpoint public domain name: {index_endpoint.public_endpoint_domain_name}\"\n",
    "#     )\n",
    "#     print(\"Deployed indexes on the index endpoint:\")\n",
    "#     for d in index_endpoint.deployed_indexes:\n",
    "#         print(f\"    {d.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: Add Document Embeddings to Matching Engine - Vector Store\n",
    "\n",
    "This step ingests and parse PDF documents, split them, generate embeddings and add the embeddings to the vector store. The document corpus used as dataset is a sample of Google published research papers across different domains - large models, traffic simulation, productivity etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ingest PDF files\n",
    "\n",
    "The document corpus is hosted on Cloud Storage bucket (at `gs://github-repo/documents/google-research-pdfs/`) and LangChain provides a convenient document loader [`GCSDirectoryLoader`](https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/google_cloud_storage_directory.html) to load documents from a Cloud Storage bucket. The loader uses `Unstructured` package to load files of many types including pdfs, images, html and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a Google Cloud Storage bucket in your GCP project to copy the document files into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCS_BUCKET_DOCS = f\"{PROJECT_ID}-documents\"\n",
    "FOLDER_PREFIX = \"documents/google-research-pdfs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating gs://adroit-hall-301111-documents/...\n"
     ]
    }
   ],
   "source": [
    "!gsutil mb -p $PROJECT_ID -l $ME_REGION gs://$GCS_BUCKET_DOCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy document files to your bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building synchronization state...\n",
      "Starting synchronization...\n",
      "Copying gs://github-repo/documents/google-research-pdfs/a-human-centered-approach-to-developer-productivity.pdf [Content-Type=application/pdf]...\n",
      "/ [0 files][    0.0 B/  2.7 MiB]                                                \n",
      "-\n",
      "\\\n",
      "\\ [1 files][  2.7 MiB/  2.7 MiB]                                                \n",
      "Copying gs://github-repo/documents/google-research-pdfs/a-mixed-methods-approach-to-understanding-user-trust-after-voice-assistant-failures.pdf [Content-Type=application/pdf]...\n",
      "\\ [1 files][  2.7 MiB/  3.5 MiB]                                                \n",
      "|\n",
      "| [2 files][  3.5 MiB/  3.5 MiB]                                                \n",
      "Copying gs://github-repo/documents/google-research-pdfs/a-mixture-of-expert-approach-to-rl-based-dialogue-management.pdf [Content-Type=application/pdf]...\n",
      "| [2 files][  3.5 MiB/  5.0 MiB]                                                \n",
      "/\n",
      "/ [3 files][  5.0 MiB/  5.0 MiB]                                                \n",
      "Copying gs://github-repo/documents/google-research-pdfs/adaptations-of-ux-practice-to-meet-responsible-ai-challenges.pdf [Content-Type=application/pdf]...\n",
      "/ [3 files][  5.0 MiB/  5.8 MiB]                                                \n",
      "-\n",
      "\\\n",
      "\\ [4 files][  5.8 MiB/  5.8 MiB]                                                \n",
      "\n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m rsync ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying gs://github-repo/documents/google-research-pdfs/adherence-bandits.pdf [Content-Type=application/pdf]...\n",
      "\\ [4 files][  5.8 MiB/  6.6 MiB]                                                \n",
      "|\n",
      "| [5 files][  6.6 MiB/  6.6 MiB]                                                \n",
      "Copying gs://github-repo/documents/google-research-pdfs/adversarial-streaming-via-differential-privacy-and-difference-estimators.pdf [Content-Type=application/pdf]...\n",
      "| [5 files][  6.6 MiB/  7.2 MiB]                                                \n",
      "/\n",
      "/ [6 files][  7.2 MiB/  7.2 MiB]                                                \n",
      "Copying gs://github-repo/documents/google-research-pdfs/annotator-diversity-in-data-practices.pdf [Content-Type=application/pdf]...\n",
      "/ [6 files][  7.2 MiB/  7.8 MiB]                                                \n",
      "-\n",
      "- [7 files][  7.8 MiB/  7.8 MiB]                                                \n",
      "Copying gs://github-repo/documents/google-research-pdfs/bootstrapping-multilingual-semantic-parsers-using-large-language-models.pdf [Content-Type=application/pdf]...\n",
      "- [7 files][  7.8 MiB/  8.8 MiB]                                                \n",
      "\\\n",
      "\\ [8 files][  8.8 MiB/  8.8 MiB]                                                \n",
      "Copying gs://github-repo/documents/google-research-pdfs/characterizing-attribution-and-fluency-tradeoffs-for-retrieval-augmented-llms.pdf [Content-Type=application/pdf]...\n",
      "\\ [8 files][  8.8 MiB/  9.1 MiB]                                                \n",
      "|\n",
      "| [9 files][  9.1 MiB/  9.1 MiB]                                                \n",
      "Copying gs://github-repo/documents/google-research-pdfs/code-generation-for-in-place-stencils.pdf [Content-Type=application/pdf]...\n",
      "| [9 files][  9.1 MiB/ 10.0 MiB]                                                \n",
      "/\n",
      "/ [10 files][ 10.0 MiB/ 10.0 MiB]                                               \n",
      "Copying gs://github-repo/documents/google-research-pdfs/connecting-vision-and-language-with-video-localized-narratives.pdf [Content-Type=application/pdf]...\n",
      "/ [10 files][ 10.0 MiB/ 25.8 MiB]                                               \n",
      "-\n",
      "- [11 files][ 25.8 MiB/ 25.8 MiB]                                               \n",
      "Copying gs://github-repo/documents/google-research-pdfs/contrastive-learning-can-find-an-optimal-basis-for-approx-view-invariant-functions.pdf [Content-Type=application/pdf]...\n",
      "- [11 files][ 25.8 MiB/ 27.3 MiB]                                               \n",
      "\\\n",
      "\\ [12 files][ 27.3 MiB/ 27.3 MiB]                                               \n",
      "Copying gs://github-repo/documents/google-research-pdfs/cost-utility-analysis-of-deep-learning-and-trained-human-graders-for-diabetic-retinopathy.pdf [Content-Type=application/pdf]...\n",
      "\\ [12 files][ 27.3 MiB/ 29.2 MiB]    4.6 MiB/s                                  \n",
      "|\n",
      "| [13 files][ 29.2 MiB/ 29.2 MiB]    4.3 MiB/s                                  \n",
      "Copying gs://github-repo/documents/google-research-pdfs/creating-calibrating-and-validating-large-scale-microscopic-traffic-simulation.pdf [Content-Type=application/pdf]...\n",
      "| [13 files][ 29.2 MiB/ 32.2 MiB]    4.4 MiB/s                                  \n",
      "/\n",
      "/ [14 files][ 32.2 MiB/ 32.2 MiB]    4.8 MiB/s                                  \n",
      "Copying gs://github-repo/documents/google-research-pdfs/detecting-news-headline-hallucinations-with-explanations.pdf [Content-Type=application/pdf]...\n",
      "/ [14 files][ 32.2 MiB/ 33.3 MiB]    5.4 MiB/s                                  \n",
      "-\n",
      "- [15 files][ 33.3 MiB/ 33.3 MiB]    4.9 MiB/s                                  \n",
      "Copying gs://github-repo/documents/google-research-pdfs/development-of-a-ml-model-for-sonographic-assessment-of-gestational-age.pdf [Content-Type=application/pdf]...\n",
      "- [15 files][ 33.3 MiB/ 34.2 MiB]    5.5 MiB/s                                  \n",
      "\\\n",
      "\\ [16 files][ 34.2 MiB/ 34.2 MiB]    4.9 MiB/s                                  \n",
      "Copying gs://github-repo/documents/google-research-pdfs/differentially-private-continual-releases-of-streaming-freq-moment-estimations.pdf [Content-Type=application/pdf]...\n",
      "\\ [16 files][ 34.2 MiB/ 34.8 MiB]    5.0 MiB/s                                  \n",
      "|\n",
      "| [17 files][ 34.8 MiB/ 34.8 MiB]    1.9 MiB/s                                  \n",
      "Copying gs://github-repo/documents/google-research-pdfs/how-ai-language-models-can-enhance-or-impede-communication-for-aac-users.pdf [Content-Type=application/pdf]...\n",
      "| [17 files][ 34.8 MiB/ 36.3 MiB]    1.9 MiB/s                                  \n",
      "/\n",
      "-\n",
      "- [18 files][ 36.3 MiB/ 36.3 MiB]    1.5 MiB/s                                  \n",
      "Copying gs://github-repo/documents/google-research-pdfs/increasing-impact-of-mobile-health-programs.pdf [Content-Type=application/pdf]...\n",
      "- [18 files][ 36.3 MiB/ 40.2 MiB]    1.5 MiB/s                                  \n",
      "\\\n",
      "\\ [19 files][ 40.2 MiB/ 40.2 MiB]    1.7 MiB/s                                  \n",
      "Copying gs://github-repo/documents/google-research-pdfs/making-computer-science-data-fair.pdf [Content-Type=application/pdf]...\n",
      "\\ [19 files][ 40.2 MiB/ 40.6 MiB]    1.7 MiB/s                                  \n",
      "|\n",
      "| [20 files][ 40.6 MiB/ 40.6 MiB]    1.5 MiB/s                                  \n",
      "\n",
      "Operation completed over 20 objects/40.6 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil rsync -r gs://github-repo/documents/google-research-pdfs/ gs://$GCS_BUCKET_DOCS/$FOLDER_PREFIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load documents and add document metadata such as file name, to be retrieved later when citing the references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing documents from adroit-hall-301111-documents\n",
      "# of documents loaded (pre-chunking) = 20\n"
     ]
    }
   ],
   "source": [
    "# Ingest PDF files\n",
    "\n",
    "print(f\"Processing documents from {GCS_BUCKET_DOCS}\")\n",
    "loader = GCSDirectoryLoader(\n",
    "    project_name=PROJECT_ID, bucket=GCS_BUCKET_DOCS, prefix=FOLDER_PREFIX\n",
    ")\n",
    "documents = loader.load()\n",
    "\n",
    "# Add document name and source to the metadata\n",
    "for document in tqdm(documents):\n",
    "    doc_md = document.metadata\n",
    "    document_name = doc_md[\"source\"].split(\"/\")[-1]\n",
    "    # derive doc source from Document loader\n",
    "    doc_source_prefix = \"/\".join(GCS_BUCKET_DOCS.split(\"/\")[:3])\n",
    "    doc_source_suffix = \"/\".join(doc_md[\"source\"].split(\"/\")[4:-1])\n",
    "    source = f\"{doc_source_prefix}/{doc_source_suffix}\"\n",
    "    document.metadata = {\"source\": source, \"document_name\": document_name}\n",
    "\n",
    "print(f\"# of documents loaded (pre-chunking) = {len(documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify document metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'adroit-hall-301111-documents/google-research-pdfs',\n",
       " 'document_name': 'a-human-centered-approach-to-developer-productivity.pdf'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chunk documents\n",
    "\n",
    "Split the documents to smaller chunks. When splitting the document, ensure a few chunks can fit within the context length of LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of documents = 2093\n"
     ]
    }
   ],
   "source": [
    "# split the documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=50,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"],\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(documents)\n",
    "\n",
    "# Add chunk number to metadata\n",
    "for idx, split in enumerate(doc_splits):\n",
    "    split.metadata[\"chunk\"] = idx\n",
    "\n",
    "print(f\"# of documents = {len(doc_splits)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'adroit-hall-301111-documents/google-research-pdfs',\n",
       " 'document_name': 'a-human-centered-approach-to-developer-productivity.pdf',\n",
       " 'chunk': 0}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_splits[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 a-human-centered-approach-to-developer-productivity.pdf 961\n",
      "1 a-human-centered-approach-to-developer-productivity.pdf 959\n",
      "2 a-human-centered-approach-to-developer-productivity.pdf 878\n",
      "3 a-human-centered-approach-to-developer-productivity.pdf 969\n",
      "4 a-human-centered-approach-to-developer-productivity.pdf 669\n",
      "5 a-human-centered-approach-to-developer-productivity.pdf 434\n",
      "6 a-human-centered-approach-to-developer-productivity.pdf 898\n",
      "7 a-human-centered-approach-to-developer-productivity.pdf 142\n",
      "8 a-human-centered-approach-to-developer-productivity.pdf 790\n",
      "9 a-human-centered-approach-to-developer-productivity.pdf 735\n"
     ]
    }
   ],
   "source": [
    "# See how the texts are split\n",
    "for i in range(0,10):\n",
    "    print(i, doc_splits[i].metadata['document_name'], len(doc_splits[i].page_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure Matching Engine as Vector Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Matching Engine vector store with text embeddings model. These are updated for the original MatchingEngine class\n",
    "\n",
    "- As of time of writing (2023-10-22), there is a bug in langchain `MachineEngine` class causing `add_texts` to fail during json append\n",
    "- On the other hand, updating the key for metadata as `restricts` following GCP's documentation. See [here](https://cloud.google.com/vertex-ai/docs/vector-search/filtering)\n",
    "- ID can be updated according to the use case concerned to avoid duplicated search result for the same document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TYPE_CHECKING, Any, Iterable, List, Optional, Type\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "class CustomMatchingEngine(MatchingEngine):\n",
    "\n",
    "    def add_texts(\n",
    "        self,\n",
    "        texts: Iterable[str],\n",
    "        metadatas: Optional[List[dict]] = None,\n",
    "\n",
    "        **kwargs: Any,\n",
    "    ) -> List[str]:\n",
    "        \"\"\"Run more texts through the embeddings and add to the vectorstore.\n",
    "\n",
    "        Args:\n",
    "            texts: Iterable of strings to add to the vectorstore.\n",
    "            metadatas: Optional list of metadatas associated with the texts.\n",
    "            kwargs: vectorstore specific parameters.\n",
    "\n",
    "        Returns:\n",
    "            List of ids from adding the texts into the vectorstore.\n",
    "        \"\"\"\n",
    "        texts = list(texts)\n",
    "        if metadatas is not None and len(texts) != len(metadatas):\n",
    "            raise ValueError(\n",
    "                \"texts and metadatas do not have the same length. Received \"\n",
    "                f\"{len(texts)} texts and {len(metadatas)} metadatas.\"\n",
    "            )\n",
    "        logger.debug(\"Embedding documents.\")\n",
    "        embeddings = self.embedding.embed_documents(texts)\n",
    "        jsons = []\n",
    "        ids = []\n",
    "        # Could be improved with async.\n",
    "        for idx, (embedding, text) in enumerate(zip(embeddings, texts)):\n",
    "            id = str(uuid.uuid4())\n",
    "            ids.append(id)\n",
    "            json_: dict = {\"id\": id, \"embedding\": embedding}\n",
    "            if metadatas is not None:\n",
    "                # My change on 2023-10-22: json_[\"restricts\"] for the accepted metadata field, not json_[\"metadata\"]\n",
    "                json_[\"restricts\"] = metadatas[idx]\n",
    "            # My change on 2023-10-22: jsons.append(json_), not the json module\n",
    "            jsons.append(json_)\n",
    "            self._upload_to_gcs(text, f\"documents/{id}\")\n",
    "\n",
    "        logger.debug(f\"Uploaded {len(ids)} documents to GCS.\")\n",
    "\n",
    "        # Creating json lines from the embedded documents.\n",
    "        result_str = \"\\n\".join([json.dumps(x) for x in jsons])\n",
    "\n",
    "        filename_prefix = f\"indexes/{uuid.uuid4()}\"\n",
    "        filename = f\"{filename_prefix}/{time.time()}.json\"\n",
    "        self._upload_to_gcs(result_str, filename)\n",
    "        logger.debug(\n",
    "            f\"Uploaded updated json with embeddings to \"\n",
    "            f\"{self.gcs_bucket_name}/{filename}.\"\n",
    "        )\n",
    "\n",
    "        self.index = self.index.update_embeddings(\n",
    "            contents_delta_uri=f\"gs://{self.gcs_bucket_name}/{filename_prefix}/\"\n",
    "        )\n",
    "\n",
    "        logger.debug(\"Updated index with new configuration.\")\n",
    "\n",
    "        return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Creating matching engine index with id 6862927280205725696.\n",
      "DEBUG:root:Creating endpoint with id 1217383672320098304.\n",
      "DEBUG:google.auth._default:Checking None for explicit credentials as part of auth process...\n",
      "DEBUG:google.auth._default:Checking Cloud SDK credentials as part of auth process...\n",
      "DEBUG:root:Initializing AI Platform for project adroit-hall-301111 on us-central1 and for adroit-hall-301111-me-bucket.\n"
     ]
    }
   ],
   "source": [
    "# initialize vector store\n",
    "me = CustomMatchingEngine.from_components(\n",
    "    project_id=PROJECT_ID,\n",
    "    region=ME_REGION,\n",
    "    gcs_bucket_name=f\"gs://{ME_EMBEDDING_DIR}\".split(\"/\")[2],\n",
    "    embedding=embeddings,\n",
    "    index_id=INDEX_ID,\n",
    "    endpoint_id=ENDPOINT_ID,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add documents as embeddings in Matching Engine as index\n",
    "\n",
    "The document chunks are transformed as embeddings (vectors) using Vertex AI Embeddings API and added to the index with **[streaming index update](https://cloud.google.com/vertex-ai/docs/matching-engine/create-manage-index#create-index)**. With Streaming Updates, you can update and query your index within a few seconds.\n",
    "\n",
    "The original document text is stored on Cloud Storage bucket had referenced by id."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare text and metadata to be added to the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store docs as embeddings in Matching Engine index\n",
    "# It may take a while since API is rate limited\n",
    "texts = [doc.page_content for doc in doc_splits]\n",
    "metadatas = [\n",
    "    [\n",
    "        {\"namespace\": \"source\", \"allow_list\": [doc.metadata[\"source\"]]},\n",
    "        {\"namespace\": \"document_name\", \"allow_list\": [doc.metadata[\"document_name\"]]},\n",
    "        {\"namespace\": \"chunk\", \"allow_list\": [str(doc.metadata[\"chunk\"])]},\n",
    "    ]\n",
    "    for doc in doc_splits\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add embeddings to the vector store\n",
    "\n",
    "**NOTE:** Depending on the volume and size of documents, this step may take time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Embedding documents.\n",
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"GET /storage/v1/b/adroit-hall-301111-me-bucket?projection=noAcl&prettyPrint=false HTTP/1.1\" 200 540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"POST /upload/storage/v1/b/adroit-hall-301111-me-bucket/o?uploadType=multipart HTTP/1.1\" 200 942\n",
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"GET /storage/v1/b/adroit-hall-301111-me-bucket?projection=noAcl&prettyPrint=false HTTP/1.1\" 200 540\n",
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"POST /upload/storage/v1/b/adroit-hall-301111-me-bucket/o?uploadType=multipart HTTP/1.1\" 200 942\n",
      "DEBUG:root:Uploaded 2 documents to GCS.\n",
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"GET /storage/v1/b/adroit-hall-301111-me-bucket?projection=noAcl&prettyPrint=false HTTP/1.1\" 200 540\n",
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"POST /upload/storage/v1/b/adroit-hall-301111-me-bucket/o?uploadType=multipart HTTP/1.1\" 200 1032\n",
      "DEBUG:root:Uploaded updated json with embeddings to adroit-hall-301111-me-bucket/indexes/acc5958a-925f-49be-a78c-5b713e3d2a4e/1697942560.963451.json.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating MatchingEngineIndex index: projects/712368347106/locations/us-central1/indexes/6862927280205725696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.matching_engine.matching_engine_index:Updating MatchingEngineIndex index: projects/712368347106/locations/us-central1/indexes/6862927280205725696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update MatchingEngineIndex index backing LRO: projects/712368347106/locations/us-central1/indexes/6862927280205725696/operations/1881137332812251136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.matching_engine.matching_engine_index:Update MatchingEngineIndex index backing LRO: projects/712368347106/locations/us-central1/indexes/6862927280205725696/operations/1881137332812251136\n",
      "DEBUG:google.api_core.retry:Retrying due to , sleeping 0.9s ...\n",
      "DEBUG:google.api_core.retry:Retrying due to , sleeping 0.9s ...\n",
      "DEBUG:google.api_core.retry:Retrying due to , sleeping 1.0s ...\n",
      "DEBUG:google.api_core.retry:Retrying due to , sleeping 2.0s ...\n",
      "DEBUG:google.api_core.retry:Retrying due to , sleeping 4.9s ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Yip\\Desktop\\code\\generative-ai\\test-langchain.ipynb Cell 95\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Yip/Desktop/code/generative-ai/test-langchain.ipynb#Y155sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m texts2 \u001b[39m=\u001b[39m texts[\u001b[39m0\u001b[39m:\u001b[39m2\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Yip/Desktop/code/generative-ai/test-langchain.ipynb#Y155sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m metadatas2 \u001b[39m=\u001b[39m metadatas[\u001b[39m0\u001b[39m:\u001b[39m2\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Yip/Desktop/code/generative-ai/test-langchain.ipynb#Y155sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m doc_ids \u001b[39m=\u001b[39m me\u001b[39m.\u001b[39;49madd_texts(texts\u001b[39m=\u001b[39;49mtexts2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Yip/Desktop/code/generative-ai/test-langchain.ipynb#Y155sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                     \u001b[39m#    , metadatas=metadatas2\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Yip/Desktop/code/generative-ai/test-langchain.ipynb#Y155sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                        )\n",
      "\u001b[1;32mc:\\Users\\Yip\\Desktop\\code\\generative-ai\\test-langchain.ipynb Cell 95\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Yip/Desktop/code/generative-ai/test-langchain.ipynb#Y155sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_upload_to_gcs(result_str, filename)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Yip/Desktop/code/generative-ai/test-langchain.ipynb#Y155sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m logger\u001b[39m.\u001b[39mdebug(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Yip/Desktop/code/generative-ai/test-langchain.ipynb#Y155sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUploaded updated json with embeddings to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Yip/Desktop/code/generative-ai/test-langchain.ipynb#Y155sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgcs_bucket_name\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Yip/Desktop/code/generative-ai/test-langchain.ipynb#Y155sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Yip/Desktop/code/generative-ai/test-langchain.ipynb#Y155sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mupdate_embeddings(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Yip/Desktop/code/generative-ai/test-langchain.ipynb#Y155sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     contents_delta_uri\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgs://\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgcs_bucket_name\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mfilename_prefix\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Yip/Desktop/code/generative-ai/test-langchain.ipynb#Y155sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Yip/Desktop/code/generative-ai/test-langchain.ipynb#Y155sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mUpdated index with new configuration.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Yip/Desktop/code/generative-ai/test-langchain.ipynb#Y155sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39mreturn\u001b[39;00m ids\n",
      "File \u001b[1;32mc:\\Users\\Yip\\Desktop\\code\\generative-ai\\venv\\lib\\site-packages\\google\\cloud\\aiplatform\\matching_engine\\matching_engine_index.py:350\u001b[0m, in \u001b[0;36mMatchingEngineIndex.update_embeddings\u001b[1;34m(self, contents_delta_uri, is_complete_overwrite, request_metadata)\u001b[0m\n\u001b[0;32m    340\u001b[0m update_lro \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_client\u001b[39m.\u001b[39mupdate_index(\n\u001b[0;32m    341\u001b[0m     index\u001b[39m=\u001b[39mgapic_index,\n\u001b[0;32m    342\u001b[0m     update_mask\u001b[39m=\u001b[39mupdate_mask,\n\u001b[0;32m    343\u001b[0m     metadata\u001b[39m=\u001b[39mrequest_metadata,\n\u001b[0;32m    344\u001b[0m )\n\u001b[0;32m    346\u001b[0m _LOGGER\u001b[39m.\u001b[39mlog_action_started_against_resource_with_lro(\n\u001b[0;32m    347\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mUpdate\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m, update_lro\n\u001b[0;32m    348\u001b[0m )\n\u001b[1;32m--> 350\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gca_resource \u001b[39m=\u001b[39m update_lro\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    352\u001b[0m _LOGGER\u001b[39m.\u001b[39mlog_action_completed_against_resource(\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mUpdated\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m)\n\u001b[0;32m    354\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Yip\\Desktop\\code\\generative-ai\\venv\\lib\\site-packages\\google\\api_core\\future\\polling.py:256\u001b[0m, in \u001b[0;36mPollingFuture.result\u001b[1;34m(self, timeout, retry, polling)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mresult\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_DEFAULT_VALUE, retry\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, polling\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    145\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get the result of the operation.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \n\u001b[0;32m    147\u001b[0m \u001b[39m    This method will poll for operation status periodically, blocking if\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[39m            the timeout is reached before the operation completes.\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 256\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_blocking_poll(timeout\u001b[39m=\u001b[39;49mtimeout, retry\u001b[39m=\u001b[39;49mretry, polling\u001b[39m=\u001b[39;49mpolling)\n\u001b[0;32m    258\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    259\u001b[0m         \u001b[39m# pylint: disable=raising-bad-type\u001b[39;00m\n\u001b[0;32m    260\u001b[0m         \u001b[39m# Pylint doesn't recognize that this is valid in this case.\u001b[39;00m\n\u001b[0;32m    261\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n",
      "File \u001b[1;32mc:\\Users\\Yip\\Desktop\\code\\generative-ai\\venv\\lib\\site-packages\\google\\api_core\\future\\polling.py:137\u001b[0m, in \u001b[0;36mPollingFuture._blocking_poll\u001b[1;34m(self, timeout, retry, polling)\u001b[0m\n\u001b[0;32m    134\u001b[0m     polling \u001b[39m=\u001b[39m polling\u001b[39m.\u001b[39mwith_timeout(timeout)\n\u001b[0;32m    136\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     polling(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_done_or_raise)(retry\u001b[39m=\u001b[39;49mretry)\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mRetryError:\n\u001b[0;32m    139\u001b[0m     \u001b[39mraise\u001b[39;00m concurrent\u001b[39m.\u001b[39mfutures\u001b[39m.\u001b[39mTimeoutError(\n\u001b[0;32m    140\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOperation did not complete within the designated timeout of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    141\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpolling\u001b[39m.\u001b[39mtimeout\u001b[39m}\u001b[39;00m\u001b[39m seconds.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    142\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Yip\\Desktop\\code\\generative-ai\\venv\\lib\\site-packages\\google\\api_core\\retry.py:366\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    362\u001b[0m target \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    363\u001b[0m sleep_generator \u001b[39m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    364\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initial, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maximum, multiplier\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multiplier\n\u001b[0;32m    365\u001b[0m )\n\u001b[1;32m--> 366\u001b[0m \u001b[39mreturn\u001b[39;00m retry_target(\n\u001b[0;32m    367\u001b[0m     target,\n\u001b[0;32m    368\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predicate,\n\u001b[0;32m    369\u001b[0m     sleep_generator,\n\u001b[0;32m    370\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_timeout,\n\u001b[0;32m    371\u001b[0m     on_error\u001b[39m=\u001b[39;49mon_error,\n\u001b[0;32m    372\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Yip\\Desktop\\code\\generative-ai\\venv\\lib\\site-packages\\google\\api_core\\retry.py:230\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mRetryError(\n\u001b[0;32m    221\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mDeadline of \u001b[39m\u001b[39m{:.1f}\u001b[39;00m\u001b[39ms exceeded while calling target function\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    222\u001b[0m                     timeout\n\u001b[0;32m    223\u001b[0m                 ),\n\u001b[0;32m    224\u001b[0m                 last_exc,\n\u001b[0;32m    225\u001b[0m             ) \u001b[39mfrom\u001b[39;00m \u001b[39mlast_exc\u001b[39;00m\n\u001b[0;32m    227\u001b[0m     _LOGGER\u001b[39m.\u001b[39mdebug(\n\u001b[0;32m    228\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRetrying due to \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, sleeping \u001b[39m\u001b[39m{:.1f}\u001b[39;00m\u001b[39ms ...\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(last_exc, sleep)\n\u001b[0;32m    229\u001b[0m     )\n\u001b[1;32m--> 230\u001b[0m     time\u001b[39m.\u001b[39;49msleep(sleep)\n\u001b[0;32m    232\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mSleep generator stopped yielding sleep values.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Note: This could be very long running. It took 24 mins for 2 documents\n",
    "doc_ids = me.add_texts(texts=texts[0:2], metadatas=metadatas[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate semantic search with Matching Engine is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='DEVELOPER PRODUCTIVITY FOR HUMANS\\n\\nEditor: Ciera Jaspan Google ciera@google.com\\n\\nEditor: Collin Green Google colling@google.com\\n\\nA Human-Centered Approach to Developer Productivity\\n\\nCiera Jaspan and Collin Green\\n\\nFrom the Editors\\n\\nThe “Developer Productivity for Humans” column aims to draw attention to\\n\\nadvances and challenges in research and practice in tools and practices that\\n\\nhelp improve developers’ day-to-day tasks. In this column, we reinforce that\\n\\nsoftware engineers and developers are human and productivity tools should\\n\\nsupport making their jobs easier as opposed to turning them into productivity\\n\\nmachines. We share our experiences and expertise and welcome your contribu-\\n\\ntions and feedback.\\n\\nWE LEAD A mixed-methods re- search team at Google that seeks to understand what makes engi- neers productive and happy. We explore the impact of different engineering tools, infrastructure, processes, and best practices on engineering productivity.'),\n",
       " Document(page_content='DEVELOPER PRODUCTIVITY FOR HUMANS\\n\\nEditor: Ciera Jaspan Google ciera@google.com\\n\\nEditor: Collin Green Google colling@google.com\\n\\nA Human-Centered Approach to Developer Productivity\\n\\nCiera Jaspan and Collin Green\\n\\nFrom the Editors\\n\\nThe “Developer Productivity for Humans” column aims to draw attention to\\n\\nadvances and challenges in research and practice in tools and practices that\\n\\nhelp improve developers’ day-to-day tasks. In this column, we reinforce that\\n\\nsoftware engineers and developers are human and productivity tools should\\n\\nsupport making their jobs easier as opposed to turning them into productivity\\n\\nmachines. We share our experiences and expertise and welcome your contribu-\\n\\ntions and feedback.\\n\\nWE LEAD A mixed-methods re- search team at Google that seeks to understand what makes engi- neers productive and happy. We explore the impact of different engineering tools, infrastructure, processes, and best practices on engineering productivity.')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "me.similarity_search(\"What are video localized narratives?\", k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Introduction As part of our job, we regularly meet with and advise Google leaders on what changes they should make (or should not make) to our development tools and processes. These leaders frequently wish to understand—in\\n\\nDigital Object Identifier 10.1109/MS.2022.3212165 Date of current version: 23 December 2022\\n\\nsimple terms—whether productivity is up, down, or stable. They want to know whether their particular tool is making an impact (for example, “Is my framework making develop- ers more productive?”). They hope to see a single metric that clearly goes up or down (and they want “up” and “down” to map unambiguously to “good” and “bad”). Alas, we fre- quently disappoint them, not because of the estimated effect of their sys- tem, but because of the uncertainty around such effects; uncertainty that comes from the fact that mea- suring developer productivity is in- herently difficult.\\n\\nWhy is it so difficult to measure\\n\\ndeveloper productivity?'),\n",
       " Document(page_content='Introduction As part of our job, we regularly meet with and advise Google leaders on what changes they should make (or should not make) to our development tools and processes. These leaders frequently wish to understand—in\\n\\nDigital Object Identifier 10.1109/MS.2022.3212165 Date of current version: 23 December 2022\\n\\nsimple terms—whether productivity is up, down, or stable. They want to know whether their particular tool is making an impact (for example, “Is my framework making develop- ers more productive?”). They hope to see a single metric that clearly goes up or down (and they want “up” and “down” to map unambiguously to “good” and “bad”). Alas, we fre- quently disappoint them, not because of the estimated effect of their sys- tem, but because of the uncertainty around such effects; uncertainty that comes from the fact that mea- suring developer productivity is in- herently difficult.\\n\\nWhy is it so difficult to measure\\n\\ndeveloper productivity?')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "me.similarity_search(\"What is NFC?\", k=2, search_distance=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3: Retrieval based Question/Answering Chain\n",
    "\n",
    "LangChain provides easy ways to chain multiple tasks that can do QA over a set of documents, called QA chains. The notebook works with [**RetrievalQA**](https://python.langchain.com/en/latest/modules/chains/index_examples/vector_db_qa.html) chain which is based on **load_qa_chain** under the hood.\n",
    "\n",
    "In the retrieval augmented generation chain, the Matching Engine uses semantic search to retrieve relevant documents based on the user's question. The resulting documents are then added as additional context to the prompt sent to the LLM, along with the user's question, to generate a response. Thus the response generated by LLM is grounded to your documents in the corpus.\n",
    "\n",
    "This way, a user would only need to provide their question as a prompt and the retrieval chain would be able to seek the answers using Matching Engine directly, and return a proper text response answering the question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure Question/Answering Chain with Vector Store using Text\n",
    "\n",
    "Define Matching Engine Vector Store as retriever that takes in a query and returns a list of relevant documents. The retriever implementation supports configuring number of documents to fetch and filtering by search distance as a threshold value parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create chain to answer questions\n",
    "NUMBER_OF_RESULTS = 10\n",
    "SEARCH_DISTANCE_THRESHOLD = 0.6\n",
    "\n",
    "# Expose index to the retriever\n",
    "retriever = me.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\n",
    "        \"k\": NUMBER_OF_RESULTS,\n",
    "        \"search_distance\": SEARCH_DISTANCE_THRESHOLD,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customize the default retrieval prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"SYSTEM: You are an intelligent assistant helping the users with their questions on research papers.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Strictly Use ONLY the following pieces of context to answer the question at the end. Think step-by-step and then answer.\n",
    "\n",
    "Do not try to make up an answer:\n",
    " - If the answer to the question cannot be determined from the context alone, say \"I cannot determine the answer to that.\"\n",
    " - If the context is empty, just say \"I do not know the answer to that.\"\n",
    "\n",
    "=============\n",
    "{context}\n",
    "=============\n",
    "\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure RetrievalQA chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses LLM to synthesize results from the search index.\n",
    "# Use Vertex PaLM Text API for LLM\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    verbose=True,\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": PromptTemplate(\n",
    "            template=template,\n",
    "            input_variables=[\"context\", \"question\"],\n",
    "        ),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enable verbose logging for debugging and troubleshooting the chains which includes the complete prompt to the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable for troubleshooting\n",
    "qa.combine_documents_chain.verbose = True\n",
    "qa.combine_documents_chain.llm_chain.verbose = True\n",
    "qa.combine_documents_chain.llm_chain.llm.verbose = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility function to format the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatter(result):\n",
    "    print(f\"Query: {result['query']}\")\n",
    "    print(\".\" * 80)\n",
    "    if \"source_documents\" in result.keys():\n",
    "        for idx, ref in enumerate(result[\"source_documents\"]):\n",
    "            print(\"-\" * 80)\n",
    "            print(f\"REFERENCE #{idx}\")\n",
    "            print(\"-\" * 80)\n",
    "            if \"score\" in ref.metadata:\n",
    "                print(f\"Matching Score: {ref.metadata['score']}\")\n",
    "            if \"source\" in ref.metadata:\n",
    "                print(f\"Document Source: {ref.metadata['source']}\")\n",
    "            if \"document_name\" in ref.metadata:\n",
    "                print(f\"Document Name: {ref.metadata['document_name']}\")\n",
    "            print(\".\" * 80)\n",
    "            print(f\"Content: \\n{wrap(ref.page_content)}\")\n",
    "    print(\".\" * 80)\n",
    "    print(f\"Response: {wrap(result['result'])}\")\n",
    "    print(\".\" * 80)\n",
    "\n",
    "\n",
    "def wrap(s):\n",
    "    return \"\\n\".join(textwrap.wrap(s, width=120, break_long_words=False))\n",
    "\n",
    "\n",
    "def ask(query, qa=qa, k=NUMBER_OF_RESULTS, search_distance=SEARCH_DISTANCE_THRESHOLD):\n",
    "    qa.retriever.search_kwargs[\"search_distance\"] = search_distance\n",
    "    qa.retriever.search_kwargs[\"k\"] = k\n",
    "    result = qa({\"query\": query})\n",
    "    return formatter(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run QA chain on sample questions\n",
    "\n",
    "Following are sample questions you could try. Wehn you run the query, RetrievalQA chain takes the user question, call the retriever to fetch top *k* semantically similar texts from the Matching Engine Index (vector store) and passes to the LLM as part of the prompt. The final prompt sent to the LLM looks of this format:\n",
    "\n",
    "```\n",
    "SYSTEM: {system}\n",
    "\n",
    "=============\n",
    "{context}\n",
    "=============\n",
    "\n",
    "Question: {question}\n",
    "Helpful Answer:\n",
    "```\n",
    "\n",
    "where:\n",
    " - `system`: Instructions for LLM on how to respond to the question based on the context\n",
    " - `context`: Semantically similar text (a.k.a snippets) retreived from the vector store\n",
    " - `question`: question posed by the user\n",
    "\n",
    "\n",
    "The response returned from the LLM includes both the response and references that lead to the response. This way the response from LLM is always grounded to the sources. Here we have formatted the response as:\n",
    "\n",
    "```\n",
    "Question: {question}\n",
    "--------------------------------------------------------------------------------\n",
    "REFERENCE #n\n",
    "--------------------------------------------------------------------------------\n",
    "Matching Score: <score>\n",
    "Document Source: <document source location>\n",
    "Document Name: <document file name>\n",
    "................................................................................\n",
    "Context:\n",
    "{}\n",
    "................................................................................\n",
    "Response: <answer returned by the LLM>\n",
    "................................................................................\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "Waiting\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSYSTEM: You are an intelligent assistant helping the users with their questions on research papers.\n",
      "\n",
      "Question: describe why it is difficult to measure productivity\n",
      "\n",
      "Strictly Use ONLY the following pieces of context to answer the question at the end. Think step-by-step and then answer.\n",
      "\n",
      "Do not try to make up an answer:\n",
      " - If the answer to the question cannot be determined from the context alone, say \"I cannot determine the answer to that.\"\n",
      " - If the context is empty, just say \"I do not know the answer to that.\"\n",
      "\n",
      "=============\n",
      "Introduction As part of our job, we regularly meet with and advise Google leaders on what changes they should make (or should not make) to our development tools and processes. These leaders frequently wish to understand—in\n",
      "\n",
      "Digital Object Identifier 10.1109/MS.2022.3212165 Date of current version: 23 December 2022\n",
      "\n",
      "simple terms—whether productivity is up, down, or stable. They want to know whether their particular tool is making an impact (for example, “Is my framework making develop- ers more productive?”). They hope to see a single metric that clearly goes up or down (and they want “up” and “down” to map unambiguously to “good” and “bad”). Alas, we fre- quently disappoint them, not because of the estimated effect of their sys- tem, but because of the uncertainty around such effects; uncertainty that comes from the fact that mea- suring developer productivity is in- herently difficult.\n",
      "\n",
      "Why is it so difficult to measure\n",
      "\n",
      "developer productivity?\n",
      "\n",
      "Introduction As part of our job, we regularly meet with and advise Google leaders on what changes they should make (or should not make) to our development tools and processes. These leaders frequently wish to understand—in\n",
      "\n",
      "Digital Object Identifier 10.1109/MS.2022.3212165 Date of current version: 23 December 2022\n",
      "\n",
      "simple terms—whether productivity is up, down, or stable. They want to know whether their particular tool is making an impact (for example, “Is my framework making develop- ers more productive?”). They hope to see a single metric that clearly goes up or down (and they want “up” and “down” to map unambiguously to “good” and “bad”). Alas, we fre- quently disappoint them, not because of the estimated effect of their sys- tem, but because of the uncertainty around such effects; uncertainty that comes from the fact that mea- suring developer productivity is in- herently difficult.\n",
      "\n",
      "Why is it so difficult to measure\n",
      "\n",
      "developer productivity?\n",
      "\n",
      "Introduction As part of our job, we regularly meet with and advise Google leaders on what changes they should make (or should not make) to our development tools and processes. These leaders frequently wish to understand—in\n",
      "\n",
      "Digital Object Identifier 10.1109/MS.2022.3212165 Date of current version: 23 December 2022\n",
      "\n",
      "simple terms—whether productivity is up, down, or stable. They want to know whether their particular tool is making an impact (for example, “Is my framework making develop- ers more productive?”). They hope to see a single metric that clearly goes up or down (and they want “up” and “down” to map unambiguously to “good” and “bad”). Alas, we fre- quently disappoint them, not because of the estimated effect of their sys- tem, but because of the uncertainty around such effects; uncertainty that comes from the fact that mea- suring developer productivity is in- herently difficult.\n",
      "\n",
      "Why is it so difficult to measure\n",
      "\n",
      "developer productivity?\n",
      "\n",
      "Introduction As part of our job, we regularly meet with and advise Google leaders on what changes they should make (or should not make) to our development tools and processes. These leaders frequently wish to understand—in\n",
      "\n",
      "Digital Object Identifier 10.1109/MS.2022.3212165 Date of current version: 23 December 2022\n",
      "\n",
      "simple terms—whether productivity is up, down, or stable. They want to know whether their particular tool is making an impact (for example, “Is my framework making develop- ers more productive?”). They hope to see a single metric that clearly goes up or down (and they want “up” and “down” to map unambiguously to “good” and “bad”). Alas, we fre- quently disappoint them, not because of the estimated effect of their sys- tem, but because of the uncertainty around such effects; uncertainty that comes from the fact that mea- suring developer productivity is in- herently difficult.\n",
      "\n",
      "Why is it so difficult to measure\n",
      "\n",
      "developer productivity?\n",
      "\n",
      "Introduction As part of our job, we regularly meet with and advise Google leaders on what changes they should make (or should not make) to our development tools and processes. These leaders frequently wish to understand—in\n",
      "\n",
      "Digital Object Identifier 10.1109/MS.2022.3212165 Date of current version: 23 December 2022\n",
      "\n",
      "simple terms—whether productivity is up, down, or stable. They want to know whether their particular tool is making an impact (for example, “Is my framework making develop- ers more productive?”). They hope to see a single metric that clearly goes up or down (and they want “up” and “down” to map unambiguously to “good” and “bad”). Alas, we fre- quently disappoint them, not because of the estimated effect of their sys- tem, but because of the uncertainty around such effects; uncertainty that comes from the fact that mea- suring developer productivity is in- herently difficult.\n",
      "\n",
      "Why is it so difficult to measure\n",
      "\n",
      "developer productivity?\n",
      "\n",
      "DEVELOPER PRODUCTIVITY FOR HUMANS\n",
      "\n",
      "Editor: Ciera Jaspan Google ciera@google.com\n",
      "\n",
      "Editor: Collin Green Google colling@google.com\n",
      "\n",
      "A Human-Centered Approach to Developer Productivity\n",
      "\n",
      "Ciera Jaspan and Collin Green\n",
      "\n",
      "From the Editors\n",
      "\n",
      "The “Developer Productivity for Humans” column aims to draw attention to\n",
      "\n",
      "advances and challenges in research and practice in tools and practices that\n",
      "\n",
      "help improve developers’ day-to-day tasks. In this column, we reinforce that\n",
      "\n",
      "software engineers and developers are human and productivity tools should\n",
      "\n",
      "support making their jobs easier as opposed to turning them into productivity\n",
      "\n",
      "machines. We share our experiences and expertise and welcome your contribu-\n",
      "\n",
      "tions and feedback.\n",
      "\n",
      "WE LEAD A mixed-methods re- search team at Google that seeks to understand what makes engi- neers productive and happy. We explore the impact of different engineering tools, infrastructure, processes, and best practices on engineering productivity.\n",
      "\n",
      "DEVELOPER PRODUCTIVITY FOR HUMANS\n",
      "\n",
      "Editor: Ciera Jaspan Google ciera@google.com\n",
      "\n",
      "Editor: Collin Green Google colling@google.com\n",
      "\n",
      "A Human-Centered Approach to Developer Productivity\n",
      "\n",
      "Ciera Jaspan and Collin Green\n",
      "\n",
      "From the Editors\n",
      "\n",
      "The “Developer Productivity for Humans” column aims to draw attention to\n",
      "\n",
      "advances and challenges in research and practice in tools and practices that\n",
      "\n",
      "help improve developers’ day-to-day tasks. In this column, we reinforce that\n",
      "\n",
      "software engineers and developers are human and productivity tools should\n",
      "\n",
      "support making their jobs easier as opposed to turning them into productivity\n",
      "\n",
      "machines. We share our experiences and expertise and welcome your contribu-\n",
      "\n",
      "tions and feedback.\n",
      "\n",
      "WE LEAD A mixed-methods re- search team at Google that seeks to understand what makes engi- neers productive and happy. We explore the impact of different engineering tools, infrastructure, processes, and best practices on engineering productivity.\n",
      "\n",
      "DEVELOPER PRODUCTIVITY FOR HUMANS\n",
      "\n",
      "Editor: Ciera Jaspan Google ciera@google.com\n",
      "\n",
      "Editor: Collin Green Google colling@google.com\n",
      "\n",
      "A Human-Centered Approach to Developer Productivity\n",
      "\n",
      "Ciera Jaspan and Collin Green\n",
      "\n",
      "From the Editors\n",
      "\n",
      "The “Developer Productivity for Humans” column aims to draw attention to\n",
      "\n",
      "advances and challenges in research and practice in tools and practices that\n",
      "\n",
      "help improve developers’ day-to-day tasks. In this column, we reinforce that\n",
      "\n",
      "software engineers and developers are human and productivity tools should\n",
      "\n",
      "support making their jobs easier as opposed to turning them into productivity\n",
      "\n",
      "machines. We share our experiences and expertise and welcome your contribu-\n",
      "\n",
      "tions and feedback.\n",
      "\n",
      "WE LEAD A mixed-methods re- search team at Google that seeks to understand what makes engi- neers productive and happy. We explore the impact of different engineering tools, infrastructure, processes, and best practices on engineering productivity.\n",
      "\n",
      "DEVELOPER PRODUCTIVITY FOR HUMANS\n",
      "\n",
      "Editor: Ciera Jaspan Google ciera@google.com\n",
      "\n",
      "Editor: Collin Green Google colling@google.com\n",
      "\n",
      "A Human-Centered Approach to Developer Productivity\n",
      "\n",
      "Ciera Jaspan and Collin Green\n",
      "\n",
      "From the Editors\n",
      "\n",
      "The “Developer Productivity for Humans” column aims to draw attention to\n",
      "\n",
      "advances and challenges in research and practice in tools and practices that\n",
      "\n",
      "help improve developers’ day-to-day tasks. In this column, we reinforce that\n",
      "\n",
      "software engineers and developers are human and productivity tools should\n",
      "\n",
      "support making their jobs easier as opposed to turning them into productivity\n",
      "\n",
      "machines. We share our experiences and expertise and welcome your contribu-\n",
      "\n",
      "tions and feedback.\n",
      "\n",
      "WE LEAD A mixed-methods re- search team at Google that seeks to understand what makes engi- neers productive and happy. We explore the impact of different engineering tools, infrastructure, processes, and best practices on engineering productivity.\n",
      "\n",
      "DEVELOPER PRODUCTIVITY FOR HUMANS\n",
      "\n",
      "Editor: Ciera Jaspan Google ciera@google.com\n",
      "\n",
      "Editor: Collin Green Google colling@google.com\n",
      "\n",
      "A Human-Centered Approach to Developer Productivity\n",
      "\n",
      "Ciera Jaspan and Collin Green\n",
      "\n",
      "From the Editors\n",
      "\n",
      "The “Developer Productivity for Humans” column aims to draw attention to\n",
      "\n",
      "advances and challenges in research and practice in tools and practices that\n",
      "\n",
      "help improve developers’ day-to-day tasks. In this column, we reinforce that\n",
      "\n",
      "software engineers and developers are human and productivity tools should\n",
      "\n",
      "support making their jobs easier as opposed to turning them into productivity\n",
      "\n",
      "machines. We share our experiences and expertise and welcome your contribu-\n",
      "\n",
      "tions and feedback.\n",
      "\n",
      "WE LEAD A mixed-methods re- search team at Google that seeks to understand what makes engi- neers productive and happy. We explore the impact of different engineering tools, infrastructure, processes, and best practices on engineering productivity.\n",
      "=============\n",
      "\n",
      "Question: describe why it is difficult to measure productivity\n",
      "Helpful Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Query: describe why it is difficult to measure productivity\n",
      "................................................................................\n",
      "--------------------------------------------------------------------------------\n",
      "REFERENCE #0\n",
      "--------------------------------------------------------------------------------\n",
      "................................................................................\n",
      "Content: \n",
      "Introduction As part of our job, we regularly meet with and advise Google leaders on what changes they should make (or\n",
      "should not make) to our development tools and processes. These leaders frequently wish to understand—in  Digital Object\n",
      "Identifier 10.1109/MS.2022.3212165 Date of current version: 23 December 2022  simple terms—whether productivity is up,\n",
      "down, or stable. They want to know whether their particular tool is making an impact (for example, “Is my framework\n",
      "making develop- ers more productive?”). They hope to see a single metric that clearly goes up or down (and they want\n",
      "“up” and “down” to map unambiguously to “good” and “bad”). Alas, we fre- quently disappoint them, not because of the\n",
      "estimated effect of their sys- tem, but because of the uncertainty around such effects; uncertainty that comes from the\n",
      "fact that mea- suring developer productivity is in- herently difficult.  Why is it so difficult to measure  developer\n",
      "productivity?\n",
      "--------------------------------------------------------------------------------\n",
      "REFERENCE #1\n",
      "--------------------------------------------------------------------------------\n",
      "................................................................................\n",
      "Content: \n",
      "Introduction As part of our job, we regularly meet with and advise Google leaders on what changes they should make (or\n",
      "should not make) to our development tools and processes. These leaders frequently wish to understand—in  Digital Object\n",
      "Identifier 10.1109/MS.2022.3212165 Date of current version: 23 December 2022  simple terms—whether productivity is up,\n",
      "down, or stable. They want to know whether their particular tool is making an impact (for example, “Is my framework\n",
      "making develop- ers more productive?”). They hope to see a single metric that clearly goes up or down (and they want\n",
      "“up” and “down” to map unambiguously to “good” and “bad”). Alas, we fre- quently disappoint them, not because of the\n",
      "estimated effect of their sys- tem, but because of the uncertainty around such effects; uncertainty that comes from the\n",
      "fact that mea- suring developer productivity is in- herently difficult.  Why is it so difficult to measure  developer\n",
      "productivity?\n",
      "--------------------------------------------------------------------------------\n",
      "REFERENCE #2\n",
      "--------------------------------------------------------------------------------\n",
      "................................................................................\n",
      "Content: \n",
      "Introduction As part of our job, we regularly meet with and advise Google leaders on what changes they should make (or\n",
      "should not make) to our development tools and processes. These leaders frequently wish to understand—in  Digital Object\n",
      "Identifier 10.1109/MS.2022.3212165 Date of current version: 23 December 2022  simple terms—whether productivity is up,\n",
      "down, or stable. They want to know whether their particular tool is making an impact (for example, “Is my framework\n",
      "making develop- ers more productive?”). They hope to see a single metric that clearly goes up or down (and they want\n",
      "“up” and “down” to map unambiguously to “good” and “bad”). Alas, we fre- quently disappoint them, not because of the\n",
      "estimated effect of their sys- tem, but because of the uncertainty around such effects; uncertainty that comes from the\n",
      "fact that mea- suring developer productivity is in- herently difficult.  Why is it so difficult to measure  developer\n",
      "productivity?\n",
      "--------------------------------------------------------------------------------\n",
      "REFERENCE #3\n",
      "--------------------------------------------------------------------------------\n",
      "................................................................................\n",
      "Content: \n",
      "Introduction As part of our job, we regularly meet with and advise Google leaders on what changes they should make (or\n",
      "should not make) to our development tools and processes. These leaders frequently wish to understand—in  Digital Object\n",
      "Identifier 10.1109/MS.2022.3212165 Date of current version: 23 December 2022  simple terms—whether productivity is up,\n",
      "down, or stable. They want to know whether their particular tool is making an impact (for example, “Is my framework\n",
      "making develop- ers more productive?”). They hope to see a single metric that clearly goes up or down (and they want\n",
      "“up” and “down” to map unambiguously to “good” and “bad”). Alas, we fre- quently disappoint them, not because of the\n",
      "estimated effect of their sys- tem, but because of the uncertainty around such effects; uncertainty that comes from the\n",
      "fact that mea- suring developer productivity is in- herently difficult.  Why is it so difficult to measure  developer\n",
      "productivity?\n",
      "--------------------------------------------------------------------------------\n",
      "REFERENCE #4\n",
      "--------------------------------------------------------------------------------\n",
      "................................................................................\n",
      "Content: \n",
      "Introduction As part of our job, we regularly meet with and advise Google leaders on what changes they should make (or\n",
      "should not make) to our development tools and processes. These leaders frequently wish to understand—in  Digital Object\n",
      "Identifier 10.1109/MS.2022.3212165 Date of current version: 23 December 2022  simple terms—whether productivity is up,\n",
      "down, or stable. They want to know whether their particular tool is making an impact (for example, “Is my framework\n",
      "making develop- ers more productive?”). They hope to see a single metric that clearly goes up or down (and they want\n",
      "“up” and “down” to map unambiguously to “good” and “bad”). Alas, we fre- quently disappoint them, not because of the\n",
      "estimated effect of their sys- tem, but because of the uncertainty around such effects; uncertainty that comes from the\n",
      "fact that mea- suring developer productivity is in- herently difficult.  Why is it so difficult to measure  developer\n",
      "productivity?\n",
      "--------------------------------------------------------------------------------\n",
      "REFERENCE #5\n",
      "--------------------------------------------------------------------------------\n",
      "................................................................................\n",
      "Content: \n",
      "DEVELOPER PRODUCTIVITY FOR HUMANS  Editor: Ciera Jaspan Google ciera@google.com  Editor: Collin Green Google\n",
      "colling@google.com  A Human-Centered Approach to Developer Productivity  Ciera Jaspan and Collin Green  From the Editors\n",
      "The “Developer Productivity for Humans” column aims to draw attention to  advances and challenges in research and\n",
      "practice in tools and practices that  help improve developers’ day-to-day tasks. In this column, we reinforce that\n",
      "software engineers and developers are human and productivity tools should  support making their jobs easier as opposed\n",
      "to turning them into productivity  machines. We share our experiences and expertise and welcome your contribu-  tions\n",
      "and feedback.  WE LEAD A mixed-methods re- search team at Google that seeks to understand what makes engi- neers\n",
      "productive and happy. We explore the impact of different engineering tools, infrastructure, processes, and best\n",
      "practices on engineering productivity.\n",
      "--------------------------------------------------------------------------------\n",
      "REFERENCE #6\n",
      "--------------------------------------------------------------------------------\n",
      "................................................................................\n",
      "Content: \n",
      "DEVELOPER PRODUCTIVITY FOR HUMANS  Editor: Ciera Jaspan Google ciera@google.com  Editor: Collin Green Google\n",
      "colling@google.com  A Human-Centered Approach to Developer Productivity  Ciera Jaspan and Collin Green  From the Editors\n",
      "The “Developer Productivity for Humans” column aims to draw attention to  advances and challenges in research and\n",
      "practice in tools and practices that  help improve developers’ day-to-day tasks. In this column, we reinforce that\n",
      "software engineers and developers are human and productivity tools should  support making their jobs easier as opposed\n",
      "to turning them into productivity  machines. We share our experiences and expertise and welcome your contribu-  tions\n",
      "and feedback.  WE LEAD A mixed-methods re- search team at Google that seeks to understand what makes engi- neers\n",
      "productive and happy. We explore the impact of different engineering tools, infrastructure, processes, and best\n",
      "practices on engineering productivity.\n",
      "--------------------------------------------------------------------------------\n",
      "REFERENCE #7\n",
      "--------------------------------------------------------------------------------\n",
      "................................................................................\n",
      "Content: \n",
      "DEVELOPER PRODUCTIVITY FOR HUMANS  Editor: Ciera Jaspan Google ciera@google.com  Editor: Collin Green Google\n",
      "colling@google.com  A Human-Centered Approach to Developer Productivity  Ciera Jaspan and Collin Green  From the Editors\n",
      "The “Developer Productivity for Humans” column aims to draw attention to  advances and challenges in research and\n",
      "practice in tools and practices that  help improve developers’ day-to-day tasks. In this column, we reinforce that\n",
      "software engineers and developers are human and productivity tools should  support making their jobs easier as opposed\n",
      "to turning them into productivity  machines. We share our experiences and expertise and welcome your contribu-  tions\n",
      "and feedback.  WE LEAD A mixed-methods re- search team at Google that seeks to understand what makes engi- neers\n",
      "productive and happy. We explore the impact of different engineering tools, infrastructure, processes, and best\n",
      "practices on engineering productivity.\n",
      "--------------------------------------------------------------------------------\n",
      "REFERENCE #8\n",
      "--------------------------------------------------------------------------------\n",
      "................................................................................\n",
      "Content: \n",
      "DEVELOPER PRODUCTIVITY FOR HUMANS  Editor: Ciera Jaspan Google ciera@google.com  Editor: Collin Green Google\n",
      "colling@google.com  A Human-Centered Approach to Developer Productivity  Ciera Jaspan and Collin Green  From the Editors\n",
      "The “Developer Productivity for Humans” column aims to draw attention to  advances and challenges in research and\n",
      "practice in tools and practices that  help improve developers’ day-to-day tasks. In this column, we reinforce that\n",
      "software engineers and developers are human and productivity tools should  support making their jobs easier as opposed\n",
      "to turning them into productivity  machines. We share our experiences and expertise and welcome your contribu-  tions\n",
      "and feedback.  WE LEAD A mixed-methods re- search team at Google that seeks to understand what makes engi- neers\n",
      "productive and happy. We explore the impact of different engineering tools, infrastructure, processes, and best\n",
      "practices on engineering productivity.\n",
      "--------------------------------------------------------------------------------\n",
      "REFERENCE #9\n",
      "--------------------------------------------------------------------------------\n",
      "................................................................................\n",
      "Content: \n",
      "DEVELOPER PRODUCTIVITY FOR HUMANS  Editor: Ciera Jaspan Google ciera@google.com  Editor: Collin Green Google\n",
      "colling@google.com  A Human-Centered Approach to Developer Productivity  Ciera Jaspan and Collin Green  From the Editors\n",
      "The “Developer Productivity for Humans” column aims to draw attention to  advances and challenges in research and\n",
      "practice in tools and practices that  help improve developers’ day-to-day tasks. In this column, we reinforce that\n",
      "software engineers and developers are human and productivity tools should  support making their jobs easier as opposed\n",
      "to turning them into productivity  machines. We share our experiences and expertise and welcome your contribu-  tions\n",
      "and feedback.  WE LEAD A mixed-methods re- search team at Google that seeks to understand what makes engi- neers\n",
      "productive and happy. We explore the impact of different engineering tools, infrastructure, processes, and best\n",
      "practices on engineering productivity.\n",
      "................................................................................\n",
      "Response: The authors state that \"measuring developer productivity is in- herently difficult\" because there is no single metric\n",
      "that can capture all aspects of developer productivity. They also note that different developers may have different\n",
      "definitions of productivity, and that productivity can vary depending on the context in which developers are working.\n",
      "................................................................................\n"
     ]
    }
   ],
   "source": [
    "ask(\"describe why it is difficult to measure productivity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ask a question which is outside of the domain in the corpus. You should see something like - \"I cannot determine the answer to that\". This is because the output is conditioned in the prompts to not to respond when the question is out of the context.\n",
    "\n",
    "Following is the instructions in prompt template that is configured in the retrieval QA chain above:\n",
    "\n",
    "```\n",
    "Strictly Use ONLY the following pieces of context to answer the question at the end. Think step-by-step and then answer.\n",
    "\n",
    "Do not try to make up an answer:\n",
    " - If the answer to the question cannot be determined from the context alone, say \"I cannot determine the answer to that.\"\n",
    " - If the context is empty, just say \"I do not know the answer to that.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "Waiting\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSYSTEM: You are an intelligent assistant helping the users with their questions on research papers.\n",
      "\n",
      "Question: what is the meaning of life?\n",
      "\n",
      "Strictly Use ONLY the following pieces of context to answer the question at the end. Think step-by-step and then answer.\n",
      "\n",
      "Do not try to make up an answer:\n",
      " - If the answer to the question cannot be determined from the context alone, say \"I cannot determine the answer to that.\"\n",
      " - If the context is empty, just say \"I do not know the answer to that.\"\n",
      "\n",
      "=============\n",
      "DEVELOPER PRODUCTIVITY FOR HUMANS\n",
      "\n",
      "Editor: Ciera Jaspan Google ciera@google.com\n",
      "\n",
      "Editor: Collin Green Google colling@google.com\n",
      "\n",
      "A Human-Centered Approach to Developer Productivity\n",
      "\n",
      "Ciera Jaspan and Collin Green\n",
      "\n",
      "From the Editors\n",
      "\n",
      "The “Developer Productivity for Humans” column aims to draw attention to\n",
      "\n",
      "advances and challenges in research and practice in tools and practices that\n",
      "\n",
      "help improve developers’ day-to-day tasks. In this column, we reinforce that\n",
      "\n",
      "software engineers and developers are human and productivity tools should\n",
      "\n",
      "support making their jobs easier as opposed to turning them into productivity\n",
      "\n",
      "machines. We share our experiences and expertise and welcome your contribu-\n",
      "\n",
      "tions and feedback.\n",
      "\n",
      "WE LEAD A mixed-methods re- search team at Google that seeks to understand what makes engi- neers productive and happy. We explore the impact of different engineering tools, infrastructure, processes, and best practices on engineering productivity.\n",
      "\n",
      "DEVELOPER PRODUCTIVITY FOR HUMANS\n",
      "\n",
      "Editor: Ciera Jaspan Google ciera@google.com\n",
      "\n",
      "Editor: Collin Green Google colling@google.com\n",
      "\n",
      "A Human-Centered Approach to Developer Productivity\n",
      "\n",
      "Ciera Jaspan and Collin Green\n",
      "\n",
      "From the Editors\n",
      "\n",
      "The “Developer Productivity for Humans” column aims to draw attention to\n",
      "\n",
      "advances and challenges in research and practice in tools and practices that\n",
      "\n",
      "help improve developers’ day-to-day tasks. In this column, we reinforce that\n",
      "\n",
      "software engineers and developers are human and productivity tools should\n",
      "\n",
      "support making their jobs easier as opposed to turning them into productivity\n",
      "\n",
      "machines. We share our experiences and expertise and welcome your contribu-\n",
      "\n",
      "tions and feedback.\n",
      "\n",
      "WE LEAD A mixed-methods re- search team at Google that seeks to understand what makes engi- neers productive and happy. We explore the impact of different engineering tools, infrastructure, processes, and best practices on engineering productivity.\n",
      "\n",
      "DEVELOPER PRODUCTIVITY FOR HUMANS\n",
      "\n",
      "Editor: Ciera Jaspan Google ciera@google.com\n",
      "\n",
      "Editor: Collin Green Google colling@google.com\n",
      "\n",
      "A Human-Centered Approach to Developer Productivity\n",
      "\n",
      "Ciera Jaspan and Collin Green\n",
      "\n",
      "From the Editors\n",
      "\n",
      "The “Developer Productivity for Humans” column aims to draw attention to\n",
      "\n",
      "advances and challenges in research and practice in tools and practices that\n",
      "\n",
      "help improve developers’ day-to-day tasks. In this column, we reinforce that\n",
      "\n",
      "software engineers and developers are human and productivity tools should\n",
      "\n",
      "support making their jobs easier as opposed to turning them into productivity\n",
      "\n",
      "machines. We share our experiences and expertise and welcome your contribu-\n",
      "\n",
      "tions and feedback.\n",
      "\n",
      "WE LEAD A mixed-methods re- search team at Google that seeks to understand what makes engi- neers productive and happy. We explore the impact of different engineering tools, infrastructure, processes, and best practices on engineering productivity.\n",
      "\n",
      "DEVELOPER PRODUCTIVITY FOR HUMANS\n",
      "\n",
      "Editor: Ciera Jaspan Google ciera@google.com\n",
      "\n",
      "Editor: Collin Green Google colling@google.com\n",
      "\n",
      "A Human-Centered Approach to Developer Productivity\n",
      "\n",
      "Ciera Jaspan and Collin Green\n",
      "\n",
      "From the Editors\n",
      "\n",
      "The “Developer Productivity for Humans” column aims to draw attention to\n",
      "\n",
      "advances and challenges in research and practice in tools and practices that\n",
      "\n",
      "help improve developers’ day-to-day tasks. In this column, we reinforce that\n",
      "\n",
      "software engineers and developers are human and productivity tools should\n",
      "\n",
      "support making their jobs easier as opposed to turning them into productivity\n",
      "\n",
      "machines. We share our experiences and expertise and welcome your contribu-\n",
      "\n",
      "tions and feedback.\n",
      "\n",
      "WE LEAD A mixed-methods re- search team at Google that seeks to understand what makes engi- neers productive and happy. We explore the impact of different engineering tools, infrastructure, processes, and best practices on engineering productivity.\n",
      "\n",
      "DEVELOPER PRODUCTIVITY FOR HUMANS\n",
      "\n",
      "Editor: Ciera Jaspan Google ciera@google.com\n",
      "\n",
      "Editor: Collin Green Google colling@google.com\n",
      "\n",
      "A Human-Centered Approach to Developer Productivity\n",
      "\n",
      "Ciera Jaspan and Collin Green\n",
      "\n",
      "From the Editors\n",
      "\n",
      "The “Developer Productivity for Humans” column aims to draw attention to\n",
      "\n",
      "advances and challenges in research and practice in tools and practices that\n",
      "\n",
      "help improve developers’ day-to-day tasks. In this column, we reinforce that\n",
      "\n",
      "software engineers and developers are human and productivity tools should\n",
      "\n",
      "support making their jobs easier as opposed to turning them into productivity\n",
      "\n",
      "machines. We share our experiences and expertise and welcome your contribu-\n",
      "\n",
      "tions and feedback.\n",
      "\n",
      "WE LEAD A mixed-methods re- search team at Google that seeks to understand what makes engi- neers productive and happy. We explore the impact of different engineering tools, infrastructure, processes, and best practices on engineering productivity.\n",
      "\n",
      "Introduction As part of our job, we regularly meet with and advise Google leaders on what changes they should make (or should not make) to our development tools and processes. These leaders frequently wish to understand—in\n",
      "\n",
      "Digital Object Identifier 10.1109/MS.2022.3212165 Date of current version: 23 December 2022\n",
      "\n",
      "simple terms—whether productivity is up, down, or stable. They want to know whether their particular tool is making an impact (for example, “Is my framework making develop- ers more productive?”). They hope to see a single metric that clearly goes up or down (and they want “up” and “down” to map unambiguously to “good” and “bad”). Alas, we fre- quently disappoint them, not because of the estimated effect of their sys- tem, but because of the uncertainty around such effects; uncertainty that comes from the fact that mea- suring developer productivity is in- herently difficult.\n",
      "\n",
      "Why is it so difficult to measure\n",
      "\n",
      "developer productivity?\n",
      "\n",
      "Introduction As part of our job, we regularly meet with and advise Google leaders on what changes they should make (or should not make) to our development tools and processes. These leaders frequently wish to understand—in\n",
      "\n",
      "Digital Object Identifier 10.1109/MS.2022.3212165 Date of current version: 23 December 2022\n",
      "\n",
      "simple terms—whether productivity is up, down, or stable. They want to know whether their particular tool is making an impact (for example, “Is my framework making develop- ers more productive?”). They hope to see a single metric that clearly goes up or down (and they want “up” and “down” to map unambiguously to “good” and “bad”). Alas, we fre- quently disappoint them, not because of the estimated effect of their sys- tem, but because of the uncertainty around such effects; uncertainty that comes from the fact that mea- suring developer productivity is in- herently difficult.\n",
      "\n",
      "Why is it so difficult to measure\n",
      "\n",
      "developer productivity?\n",
      "\n",
      "Introduction As part of our job, we regularly meet with and advise Google leaders on what changes they should make (or should not make) to our development tools and processes. These leaders frequently wish to understand—in\n",
      "\n",
      "Digital Object Identifier 10.1109/MS.2022.3212165 Date of current version: 23 December 2022\n",
      "\n",
      "simple terms—whether productivity is up, down, or stable. They want to know whether their particular tool is making an impact (for example, “Is my framework making develop- ers more productive?”). They hope to see a single metric that clearly goes up or down (and they want “up” and “down” to map unambiguously to “good” and “bad”). Alas, we fre- quently disappoint them, not because of the estimated effect of their sys- tem, but because of the uncertainty around such effects; uncertainty that comes from the fact that mea- suring developer productivity is in- herently difficult.\n",
      "\n",
      "Why is it so difficult to measure\n",
      "\n",
      "developer productivity?\n",
      "\n",
      "Introduction As part of our job, we regularly meet with and advise Google leaders on what changes they should make (or should not make) to our development tools and processes. These leaders frequently wish to understand—in\n",
      "\n",
      "Digital Object Identifier 10.1109/MS.2022.3212165 Date of current version: 23 December 2022\n",
      "\n",
      "simple terms—whether productivity is up, down, or stable. They want to know whether their particular tool is making an impact (for example, “Is my framework making develop- ers more productive?”). They hope to see a single metric that clearly goes up or down (and they want “up” and “down” to map unambiguously to “good” and “bad”). Alas, we fre- quently disappoint them, not because of the estimated effect of their sys- tem, but because of the uncertainty around such effects; uncertainty that comes from the fact that mea- suring developer productivity is in- herently difficult.\n",
      "\n",
      "Why is it so difficult to measure\n",
      "\n",
      "developer productivity?\n",
      "\n",
      "Introduction As part of our job, we regularly meet with and advise Google leaders on what changes they should make (or should not make) to our development tools and processes. These leaders frequently wish to understand—in\n",
      "\n",
      "Digital Object Identifier 10.1109/MS.2022.3212165 Date of current version: 23 December 2022\n",
      "\n",
      "simple terms—whether productivity is up, down, or stable. They want to know whether their particular tool is making an impact (for example, “Is my framework making develop- ers more productive?”). They hope to see a single metric that clearly goes up or down (and they want “up” and “down” to map unambiguously to “good” and “bad”). Alas, we fre- quently disappoint them, not because of the estimated effect of their sys- tem, but because of the uncertainty around such effects; uncertainty that comes from the fact that mea- suring developer productivity is in- herently difficult.\n",
      "\n",
      "Why is it so difficult to measure\n",
      "\n",
      "developer productivity?\n",
      "=============\n",
      "\n",
      "Question: what is the meaning of life?\n",
      "Helpful Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Query: what is the meaning of life?\n",
      "................................................................................\n",
      "--------------------------------------------------------------------------------\n",
      "REFERENCE #0\n",
      "--------------------------------------------------------------------------------\n",
      "................................................................................\n",
      "Content: \n",
      "DEVELOPER PRODUCTIVITY FOR HUMANS  Editor: Ciera Jaspan Google ciera@google.com  Editor: Collin Green Google\n",
      "colling@google.com  A Human-Centered Approach to Developer Productivity  Ciera Jaspan and Collin Green  From the Editors\n",
      "The “Developer Productivity for Humans” column aims to draw attention to  advances and challenges in research and\n",
      "practice in tools and practices that  help improve developers’ day-to-day tasks. In this column, we reinforce that\n",
      "software engineers and developers are human and productivity tools should  support making their jobs easier as opposed\n",
      "to turning them into productivity  machines. We share our experiences and expertise and welcome your contribu-  tions\n",
      "and feedback.  WE LEAD A mixed-methods re- search team at Google that seeks to understand what makes engi- neers\n",
      "productive and happy. We explore the impact of different engineering tools, infrastructure, processes, and best\n",
      "practices on engineering productivity.\n",
      "--------------------------------------------------------------------------------\n",
      "REFERENCE #1\n",
      "--------------------------------------------------------------------------------\n",
      "................................................................................\n",
      "Content: \n",
      "DEVELOPER PRODUCTIVITY FOR HUMANS  Editor: Ciera Jaspan Google ciera@google.com  Editor: Collin Green Google\n",
      "colling@google.com  A Human-Centered Approach to Developer Productivity  Ciera Jaspan and Collin Green  From the Editors\n",
      "The “Developer Productivity for Humans” column aims to draw attention to  advances and challenges in research and\n",
      "practice in tools and practices that  help improve developers’ day-to-day tasks. In this column, we reinforce that\n",
      "software engineers and developers are human and productivity tools should  support making their jobs easier as opposed\n",
      "to turning them into productivity  machines. We share our experiences and expertise and welcome your contribu-  tions\n",
      "and feedback.  WE LEAD A mixed-methods re- search team at Google that seeks to understand what makes engi- neers\n",
      "productive and happy. We explore the impact of different engineering tools, infrastructure, processes, and best\n",
      "practices on engineering productivity.\n",
      "--------------------------------------------------------------------------------\n",
      "REFERENCE #2\n",
      "--------------------------------------------------------------------------------\n",
      "................................................................................\n",
      "Content: \n",
      "DEVELOPER PRODUCTIVITY FOR HUMANS  Editor: Ciera Jaspan Google ciera@google.com  Editor: Collin Green Google\n",
      "colling@google.com  A Human-Centered Approach to Developer Productivity  Ciera Jaspan and Collin Green  From the Editors\n",
      "The “Developer Productivity for Humans” column aims to draw attention to  advances and challenges in research and\n",
      "practice in tools and practices that  help improve developers’ day-to-day tasks. In this column, we reinforce that\n",
      "software engineers and developers are human and productivity tools should  support making their jobs easier as opposed\n",
      "to turning them into productivity  machines. We share our experiences and expertise and welcome your contribu-  tions\n",
      "and feedback.  WE LEAD A mixed-methods re- search team at Google that seeks to understand what makes engi- neers\n",
      "productive and happy. We explore the impact of different engineering tools, infrastructure, processes, and best\n",
      "practices on engineering productivity.\n",
      "--------------------------------------------------------------------------------\n",
      "REFERENCE #3\n",
      "--------------------------------------------------------------------------------\n",
      "................................................................................\n",
      "Content: \n",
      "DEVELOPER PRODUCTIVITY FOR HUMANS  Editor: Ciera Jaspan Google ciera@google.com  Editor: Collin Green Google\n",
      "colling@google.com  A Human-Centered Approach to Developer Productivity  Ciera Jaspan and Collin Green  From the Editors\n",
      "The “Developer Productivity for Humans” column aims to draw attention to  advances and challenges in research and\n",
      "practice in tools and practices that  help improve developers’ day-to-day tasks. In this column, we reinforce that\n",
      "software engineers and developers are human and productivity tools should  support making their jobs easier as opposed\n",
      "to turning them into productivity  machines. We share our experiences and expertise and welcome your contribu-  tions\n",
      "and feedback.  WE LEAD A mixed-methods re- search team at Google that seeks to understand what makes engi- neers\n",
      "productive and happy. We explore the impact of different engineering tools, infrastructure, processes, and best\n",
      "practices on engineering productivity.\n",
      "--------------------------------------------------------------------------------\n",
      "REFERENCE #4\n",
      "--------------------------------------------------------------------------------\n",
      "................................................................................\n",
      "Content: \n",
      "DEVELOPER PRODUCTIVITY FOR HUMANS  Editor: Ciera Jaspan Google ciera@google.com  Editor: Collin Green Google\n",
      "colling@google.com  A Human-Centered Approach to Developer Productivity  Ciera Jaspan and Collin Green  From the Editors\n",
      "The “Developer Productivity for Humans” column aims to draw attention to  advances and challenges in research and\n",
      "practice in tools and practices that  help improve developers’ day-to-day tasks. In this column, we reinforce that\n",
      "software engineers and developers are human and productivity tools should  support making their jobs easier as opposed\n",
      "to turning them into productivity  machines. We share our experiences and expertise and welcome your contribu-  tions\n",
      "and feedback.  WE LEAD A mixed-methods re- search team at Google that seeks to understand what makes engi- neers\n",
      "productive and happy. We explore the impact of different engineering tools, infrastructure, processes, and best\n",
      "practices on engineering productivity.\n",
      "--------------------------------------------------------------------------------\n",
      "REFERENCE #5\n",
      "--------------------------------------------------------------------------------\n",
      "................................................................................\n",
      "Content: \n",
      "Introduction As part of our job, we regularly meet with and advise Google leaders on what changes they should make (or\n",
      "should not make) to our development tools and processes. These leaders frequently wish to understand—in  Digital Object\n",
      "Identifier 10.1109/MS.2022.3212165 Date of current version: 23 December 2022  simple terms—whether productivity is up,\n",
      "down, or stable. They want to know whether their particular tool is making an impact (for example, “Is my framework\n",
      "making develop- ers more productive?”). They hope to see a single metric that clearly goes up or down (and they want\n",
      "“up” and “down” to map unambiguously to “good” and “bad”). Alas, we fre- quently disappoint them, not because of the\n",
      "estimated effect of their sys- tem, but because of the uncertainty around such effects; uncertainty that comes from the\n",
      "fact that mea- suring developer productivity is in- herently difficult.  Why is it so difficult to measure  developer\n",
      "productivity?\n",
      "--------------------------------------------------------------------------------\n",
      "REFERENCE #6\n",
      "--------------------------------------------------------------------------------\n",
      "................................................................................\n",
      "Content: \n",
      "Introduction As part of our job, we regularly meet with and advise Google leaders on what changes they should make (or\n",
      "should not make) to our development tools and processes. These leaders frequently wish to understand—in  Digital Object\n",
      "Identifier 10.1109/MS.2022.3212165 Date of current version: 23 December 2022  simple terms—whether productivity is up,\n",
      "down, or stable. They want to know whether their particular tool is making an impact (for example, “Is my framework\n",
      "making develop- ers more productive?”). They hope to see a single metric that clearly goes up or down (and they want\n",
      "“up” and “down” to map unambiguously to “good” and “bad”). Alas, we fre- quently disappoint them, not because of the\n",
      "estimated effect of their sys- tem, but because of the uncertainty around such effects; uncertainty that comes from the\n",
      "fact that mea- suring developer productivity is in- herently difficult.  Why is it so difficult to measure  developer\n",
      "productivity?\n",
      "--------------------------------------------------------------------------------\n",
      "REFERENCE #7\n",
      "--------------------------------------------------------------------------------\n",
      "................................................................................\n",
      "Content: \n",
      "Introduction As part of our job, we regularly meet with and advise Google leaders on what changes they should make (or\n",
      "should not make) to our development tools and processes. These leaders frequently wish to understand—in  Digital Object\n",
      "Identifier 10.1109/MS.2022.3212165 Date of current version: 23 December 2022  simple terms—whether productivity is up,\n",
      "down, or stable. They want to know whether their particular tool is making an impact (for example, “Is my framework\n",
      "making develop- ers more productive?”). They hope to see a single metric that clearly goes up or down (and they want\n",
      "“up” and “down” to map unambiguously to “good” and “bad”). Alas, we fre- quently disappoint them, not because of the\n",
      "estimated effect of their sys- tem, but because of the uncertainty around such effects; uncertainty that comes from the\n",
      "fact that mea- suring developer productivity is in- herently difficult.  Why is it so difficult to measure  developer\n",
      "productivity?\n",
      "--------------------------------------------------------------------------------\n",
      "REFERENCE #8\n",
      "--------------------------------------------------------------------------------\n",
      "................................................................................\n",
      "Content: \n",
      "Introduction As part of our job, we regularly meet with and advise Google leaders on what changes they should make (or\n",
      "should not make) to our development tools and processes. These leaders frequently wish to understand—in  Digital Object\n",
      "Identifier 10.1109/MS.2022.3212165 Date of current version: 23 December 2022  simple terms—whether productivity is up,\n",
      "down, or stable. They want to know whether their particular tool is making an impact (for example, “Is my framework\n",
      "making develop- ers more productive?”). They hope to see a single metric that clearly goes up or down (and they want\n",
      "“up” and “down” to map unambiguously to “good” and “bad”). Alas, we fre- quently disappoint them, not because of the\n",
      "estimated effect of their sys- tem, but because of the uncertainty around such effects; uncertainty that comes from the\n",
      "fact that mea- suring developer productivity is in- herently difficult.  Why is it so difficult to measure  developer\n",
      "productivity?\n",
      "--------------------------------------------------------------------------------\n",
      "REFERENCE #9\n",
      "--------------------------------------------------------------------------------\n",
      "................................................................................\n",
      "Content: \n",
      "Introduction As part of our job, we regularly meet with and advise Google leaders on what changes they should make (or\n",
      "should not make) to our development tools and processes. These leaders frequently wish to understand—in  Digital Object\n",
      "Identifier 10.1109/MS.2022.3212165 Date of current version: 23 December 2022  simple terms—whether productivity is up,\n",
      "down, or stable. They want to know whether their particular tool is making an impact (for example, “Is my framework\n",
      "making develop- ers more productive?”). They hope to see a single metric that clearly goes up or down (and they want\n",
      "“up” and “down” to map unambiguously to “good” and “bad”). Alas, we fre- quently disappoint them, not because of the\n",
      "estimated effect of their sys- tem, but because of the uncertainty around such effects; uncertainty that comes from the\n",
      "fact that mea- suring developer productivity is in- herently difficult.  Why is it so difficult to measure  developer\n",
      "productivity?\n",
      "................................................................................\n",
      "Response: I cannot determine the answer to that.\n",
      "................................................................................\n"
     ]
    }
   ],
   "source": [
    "ask(\"what is the meaning of life?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Up\n",
    "\n",
    "Please delete Matching Index and Index Endpoint after running your experiments to avoid incurring additional charges. Please note that you will be charged as long as the endpoint is running.\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ NOTE: Enabling `CLEANUP_RESOURCES` flag deletes Matching Engine Index, Index Endpoint and Cloud Storage bucket. Please run it with caution.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEANUP_RESOURCES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ME_INDEX_ID=6862927280205725696\n",
      "ME_INDEX_ENDPOINT_ID=1217383672320098304\n"
     ]
    }
   ],
   "source": [
    "mengine = MatchingEngineUtils(PROJECT_ID, ME_REGION, ME_INDEX_NAME)\n",
    "ME_INDEX_ID = INDEX_ID\n",
    "ME_INDEX_ENDPOINT_ID = ENDPOINT_ID\n",
    "print(f\"ME_INDEX_ID={ME_INDEX_ID}\")\n",
    "print(f\"ME_INDEX_ENDPOINT_ID={ME_INDEX_ENDPOINT_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Undeploy indexes and Delete index endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'@type': type.googleapis.com/google.cloud.aiplatform.v1.UndeployIndexResponse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai index-endpoints undeploy-index 1217383672320098304 \\\n",
    "  --deployed-index-id=tree_ah_deployed_unique \\\n",
    "  --project=adroit-hall-301111 \\\n",
    "  --region=us-central1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud ai index-endpoints delete 1217383672320098304 \\\n",
    "  --project=adroit-hall-301111 \\\n",
    "  --region=us-central1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Delete index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcloud ai indexes delete 6862927280205725696 \\\n",
    "  --project=adroit-hall-301111 \\\n",
    "  --region=us-central1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Delete contents from the Cloud Storage bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLEANUP_RESOURCES and \"ME_EMBEDDING_DIR\" in globals():\n",
    "    print(f\"Deleting contents from the Cloud Storage bucket {ME_EMBEDDING_DIR}\")\n",
    "    ME_EMBEDDING_BUCKET = \"/\".join(ME_EMBEDDING_DIR.split(\"/\")[:3])\n",
    "\n",
    "    shell_output = ! gsutil du -ash gs://$ME_EMBEDDING_BUCKET\n",
    "    print(shell_output)\n",
    "    print(\n",
    "        f\"Size of the bucket {ME_EMBEDDING_BUCKET} before deleting = {' '.join(shell_output[0].split()[:2])}\"\n",
    "    )\n",
    "\n",
    "    # uncomment below line to delete contents of the bucket\n",
    "    # ! gsutil -m rm -r gs://$ME_EMBEDDING_BUCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent and Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition**: The key behind agents is giving LLM's the possibility of using tools in their workflow. This is where langchain departs from the popular chatgpt implementation and we can start to get a glimpse of what it offers us as builders. Until now, we covered several building blocks in isolation. Let's see them come to life.\n",
    "\n",
    "The official definition of agents is the following:\n",
    "\n",
    "\n",
    "> Agents use an LLM to determine which actions to take and in what order. An action can either be using a tool and observing its output, or returning to the user.\n",
    "\n",
    "Here are some useful notebooks illustrating the concepts:\n",
    "- [Agents](https://github.com/pinecone-io/examples/blob/master/learn/generation/langchain/handbook/06-langchain-agents.ipynb)\n",
    "- [Custom Tools](https://github.com/pinecone-io/examples/blob/master/learn/generation/langchain/handbook/07-langchain-tools.ipynb) \n",
    "- [Example ReAct agent which uses RA as tool with conversational memory](https://colab.research.google.com/github/pinecone-io/examples/blob/master/learn/generation/langchain/handbook/08-langchain-retrieval-agent.ipynb#scrollTo=JaKTzPUEvOoy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streamlit\n",
    "Great for demo, please see `test_streamlit.py`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
